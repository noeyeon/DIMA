{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d849e0a9-05a7-496a-b357-6ccce0c07328",
   "metadata": {},
   "source": [
    "# 1. request 패키지"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "048c7692-7b8e-4c12-9df6-d4c708d87aba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "URL = 'https://www.naver.com'\n",
    "response = requests.get(URL) #get 방식으로 요청\n",
    "print(response.status_code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c32e3a2-eab3-4080-9972-b114ed81aeab",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(response.text) #네이버 홈페이지에 해당하는 html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83c2ab66-8451-4b62-a869-36391c430617",
   "metadata": {},
   "outputs": [],
   "source": [
    "URL = 'https://search.naver.com/search.naver?query=python'\n",
    "query = {'query':'python'}\n",
    "response = requests.get(URL, params=query)\n",
    "print(response.status_code)\n",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a0d2ba5-9dda-43c3-b747-ece54a62e102",
   "metadata": {},
   "source": [
    "# 2. user-agent 값 설정\n",
    "- 로봇이 아님을 나타내기 위해서 user-agent라는 값을 header에 넣어서 보냄\n",
    "- 직접적인 URL 주소로 요청 시 웹 사이트에서 웹 크롤링을 통해 접근한 것을 감지하고 접속을 차단하게 된다\n",
    "- user-agent 헤더값을 포함하여 요청하면 브라우저를 통해 요청하는 것으로 인식되어 해결\n",
    "- 웹 브라우저 실행 -> F12 개발자 모드 진입 -> Console에 navigator.userAgent 입력\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd5b4ebd-adec-476a-a3b1-877d59e40998",
   "metadata": {},
   "outputs": [],
   "source": [
    "'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/123.0.0.0 Safari/537.36'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6da3d161-d5d5-4cec-955e-6f648c354597",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "저장완료!\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "URL = 'http://www.google.com/search'\n",
    "params = {'q':'python'} #구글에서는 맵핑을 할 때 q라는 키워드에다 저장을 한다\n",
    "headers = {'user-agent':'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/123.0.0.0 Safari/537.36' } #로봇이 아님을 나타내는 user-agent값을 헤더에 넣어 보낸다\n",
    "response = requests.get(URL, params=params, headers=headers)\n",
    "response.raise_for_status() #응답코드가 200이 아니면 오류내고 멈춰라\n",
    "result = response.text\n",
    "\n",
    "with open('mygoogle.html','w', encoding='utf-8')as f: #f라는 이름에 파일 객체를 담겠다\n",
    "    f.write(result)\n",
    "print('저장완료!')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6b0dabf-6adb-4cb9-a0a2-12b6243a43b2",
   "metadata": {},
   "source": [
    "## [실습] 네이버 데이터랩에서 실시간 인기 검색어 추출"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "357fba19-0606-4980-998b-b19f1624e522",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "트위드자켓\n"
     ]
    }
   ],
   "source": [
    "#페이지에서  f12를 누르고 개발자 모드의 좌측상당의 화살표 select모드 선택 후 추출하고 싶은 단어를 클릭하면 단어의 위치를 알려준다\n",
    "\n",
    "#추출하고 싶은 정보에 바로 접근하는 건 힘들고 추출하고자 하는 정보의 상위/형제 태그를 이용해 하위/같은 레벨의 태그에 접근한다\n",
    "\n",
    "import requests\n",
    "\n",
    "response = requests.get('https://datalab.naver.com') #요청을 해야하는 웹 사이트의 주소 입력\n",
    "html_text = response.text #넘어온 응답 메세지를 html_text에 담는다\n",
    "#근접한/같은 레벨의 em이라는 class로 split(분리)한다.\n",
    "temp = html_text.split('<em class=\"num\">1</em>')[1]\n",
    "#em태그의 클래스는 num이라는 값을 가지고 있다.\n",
    "temp = temp.split('<span class=\"title\">')[1]\n",
    "#바로 위에서 만들어진 템프를 다시 <span>태그로 split, 속성들이 대부분 \"\"로 묶여 있기 때문에 ''로 묶어준다.\n",
    "temp = temp.split('</span>')[0] #다시 </span>태그로 스플릿\n",
    "print(temp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08c7a718-a40e-454d-9edd-c3500091e222",
   "metadata": {},
   "source": [
    "# 3. BeautifulSoup 패키지"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b7e2c19-b4ac-4837-ab3d-6f08ab7a1dac",
   "metadata": {},
   "source": [
    "### 3.1 Parser별 출력 결과 비교"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b98036b5-0ed2-4fab-9675-a5d73fadb516",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: lxml in c:\\users\\user\\anaconda3\\lib\\site-packages (4.9.3)\n"
     ]
    }
   ],
   "source": [
    "#!pip install html5lib\n",
    "!pip install lxml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b0a104b0-d265-4fbb-96f9-364da7f88a49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "html.parcer\n",
      "<a></a>\n",
      "----------------------------------------\n",
      "lxml\n",
      "<html><body><a></a></body></html>\n",
      "----------------------------------------\n",
      "xml\n",
      "<?xml version=\"1.0\" encoding=\"utf-8\"?>\n",
      "<a/>\n",
      "----------------------------------------\n",
      "html5lib\n",
      "<html><head></head><body><a><p></p></a></body></html>\n",
      "----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "soup = BeautifulSoup('<a></p>','html.parser')\n",
    "print('html.parcer')\n",
    "print(soup)\n",
    "print('-'*40)\n",
    "\n",
    "soup = BeautifulSoup('<a></p>','lxml')\n",
    "print('lxml')\n",
    "print(soup)\n",
    "print('-'*40)\n",
    "\n",
    "soup = BeautifulSoup('<a></p>','xml')\n",
    "print('xml')\n",
    "print(soup)\n",
    "print('-'*40)\n",
    "\n",
    "soup = BeautifulSoup('<a></p>','html5lib')\n",
    "print('html5lib')\n",
    "print(soup)\n",
    "print('-'*40)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29a928f2-c7b1-4d44-bfdf-427da93ac805",
   "metadata": {},
   "source": [
    "## 3.2 기본 사용법"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9ac0d891-55da-4200-bef2-c6216ab9f563",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<title>웹크롤러 - 위키백과, 우리 모두의 백과사전</title>\n",
      "<li id=\"footer-info-lastmod\"> 이 문서는 2023년 10월 12일 (목) 12:40에 마지막으로 편집되었습니다.</li>\n",
      " 이 문서는 2023년 10월 12일 (목) 12:40에 마지막으로 편집되었습니다.\n",
      "<a class=\"mw-jump-link\" href=\"#bodyContent\">본문으로 이동</a>\n",
      "#bodyContent\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "#위키피디아 한\n",
    "URL = 'https://ko.wikipedia.org/wiki/%EC%9B%B9%ED%81%AC%EB%A1%A4%EB%9F%AC' #마지막 부분은 유니코트도 표현된 것 -웹크롤러\n",
    "\n",
    "response = requests.get(URL)\n",
    "\n",
    "#soup 객체를 생성하기\n",
    "soup = BeautifulSoup(response.text, 'lxml')\n",
    "\n",
    "#태그를 이용한 접근\n",
    "print(soup.title)\n",
    "print(soup.footer.ul.li)\n",
    "\n",
    "#태그는 지우고 안의 값만 추출하기\n",
    "print(soup.footer.ul.li.text)\n",
    "\n",
    "#태그와 속성을 이용한 접근\n",
    "print(soup.a) #soup 객체에서 첫번째로 만나는 a태그를 출력\n",
    "\n",
    "#print(soup.a['id']) #만약 속성이 존재하지 않으면 에러 발생\n",
    "\n",
    "print(soup.a['href'])\n",
    "\n",
    "#find 함수를 이용한 태그 내의 다양한 속성을 이용한 접근\n",
    "print(soup.find('a',attrs={'title':'구글봇'})) #a태그 중 title 속성의 값이 '구글봇'인 데이터를 검색"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6caf68ca-e043-4db4-82c8-0fb3533ae50c",
   "metadata": {},
   "source": [
    "## 3.3 자식 노드를 반복 가능한 객체로 반환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fc6db867-16c8-43ba-bf55-cde652b28b0f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "<p align=\"center\" class=\"a\">text1&lt;\\p&gt;\n",
      "        <p align=\"center\" class=\"b\">text2&lt;\\p&gt;\n",
      "        <p align=\"center\" class=\"c\">text3&lt;\\p&gt;\n",
      "        <div>\n",
      "<img height=\"200\" src=\"/source\" width=\"300\"/>\n",
      "        &lt;\\div&gt;\n",
      "    &ltody&gt;\n",
      "&lt;\\html&gt;\n",
      "</div></p></p></p>\n"
     ]
    }
   ],
   "source": [
    "html = '''\n",
    "<html>\n",
    "    <head>\n",
    "        <title>Web Scrapping<\\title>\n",
    "    <\\head>\n",
    "    <body>\n",
    "        <p class=\"a\" align=\"center\">text1<\\p>\n",
    "        <p class=\"b\" align=\"center\">text2<\\p>\n",
    "        <p class=\"c\" align=\"center\">text3<\\p>\n",
    "        <div>\n",
    "            <img src=\"/source\" width=\"300\" height=\"200\">\n",
    "        <\\div>\n",
    "    <\\body>\n",
    "<\\html>\n",
    "'''\n",
    "from bs4 import BeautifulSoup\n",
    "soup = BeautifulSoup(html, 'html.parser')\n",
    "contens = soup.find('body')\n",
    "#print(contens)\n",
    "\n",
    "for child in contens.children:\n",
    "    print(child)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a42a6c25-a40f-4b01-ad9b-9cf3df69218d",
   "metadata": {},
   "source": [
    "## 3.4 자신을 포함한 부모 노드까지 출력하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ea33e8c4-ea69-430e-be33-b3ed1129dc7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<img height=\"200\" src=\"/source\" width=\"300\"/>\n",
      "\n",
      "<div>\n",
      "<img height=\"200\" src=\"/source\" width=\"300\"/>\n",
      "        &lt;\\div&gt;\n",
      "    &ltody&gt;\n",
      "&lt;\\html&gt;\n",
      "</div>\n"
     ]
    }
   ],
   "source": [
    "html = '''\n",
    "<html>\n",
    "    <head>\n",
    "        <title>Web Scrapping<\\title>\n",
    "    <\\head>\n",
    "    <body>\n",
    "        <p class=\"a\" align=\"center\">text1<\\p>\n",
    "        <p class=\"b\" align=\"center\">text2<\\p>\n",
    "        <p class=\"c\" align=\"center\">text3<\\p>\n",
    "        <div>\n",
    "            <img src=\"/source\" width=\"300\" height=\"200\">\n",
    "        <\\div>\n",
    "    <\\body>\n",
    "<\\html>\n",
    "'''\n",
    "from bs4 import BeautifulSoup\n",
    "soup = BeautifulSoup(html, 'html.parser')\n",
    "contens = soup.find('body')\n",
    "img_tag = contens.find('img')\n",
    "print(img_tag)\n",
    "print()\n",
    "print(img_tag.parent)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f82049ab-f90c-412e-a5a5-0dba36c2946a",
   "metadata": {},
   "source": [
    "## 3.5 특정 부모 노드까지 검색해서 올라감"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af6d55ac-d5e1-40a9-9fb3-aebbdeeba7e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "html = '''\n",
    "<html>\n",
    "    <head>\n",
    "        <title>Web Scrapping<\\title>\n",
    "    <\\head>\n",
    "    <body>\n",
    "        <p class=\"a\" align=\"center\">text1<\\p>\n",
    "        <p class=\"b\" align=\"center\">text2<\\p>\n",
    "        <p class=\"c\" align=\"center\">text3<\\p>\n",
    "        <div>\n",
    "            <img src=\"/source\" width=\"300\" height=\"200\">\n",
    "        <\\div>\n",
    "    <\\body>\n",
    "<\\html>\n",
    "'''\n",
    "from bs4 import BeautifulSoup\n",
    "soup = BeautifulSoup(html, 'html.parser')\n",
    "contens = soup.find('body')\n",
    "img_tag = contens.find('img')\n",
    "print(img_tag.find_parent('body')) #자기 자신을 기준으로 지정된 부모 태그까지 검색해서 올라가기"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7d111dd-4823-44fb-aee0-2dafa034eada",
   "metadata": {},
   "source": [
    "## 3.6 형제 노드 검색"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7fd4eb7c-8c50-42fa-b99e-129735b161d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<p align=\"center\" class=\"b\">text2&lt;\\p&gt;\n",
      "        <p align=\"center\" class=\"c\">text3&lt;\\p&gt;\n",
      "        <div>\n",
      "<img height=\"200\" src=\"/source\" width=\"300\"/>\n",
      "        &lt;\\div&gt;\n",
      "    &ltody&gt;\n",
      "&lt;\\html&gt;\n",
      "</div></p></p>\n",
      "-- 바로 다음 형제 노드 --\n",
      "None\n",
      "-- 모든 다음 형제 노드 --\n",
      "[]\n",
      "-- 바로 이전 형제 노드 --\n",
      "None\n",
      "-- 모든 이전 형제 노드 --\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "html = '''\n",
    "<html>\n",
    "    <head>\n",
    "        <title>Web Scrapping<\\title>\n",
    "    <\\head>\n",
    "    <body>\n",
    "        <p class=\"a\" align=\"center\">text1<\\p>\n",
    "        <p class=\"b\" align=\"center\">text2<\\p>\n",
    "        <p class=\"c\" align=\"center\">text3<\\p>\n",
    "        <div>\n",
    "            <img src=\"/source\" width=\"300\" height=\"200\">\n",
    "        <\\div>\n",
    "    <\\body>\n",
    "<\\html>\n",
    "'''\n",
    "from bs4 import BeautifulSoup\n",
    "soup = BeautifulSoup(html, 'html.parser')\n",
    "p_tag = soup.find('p', attrs={'class':'b'}) #클래스 속성의 값이 b를 가지고 있는 p태그를 찾아라\n",
    "print(p_tag)\n",
    "print('-- 바로 다음 형제 노드 --')\n",
    "print(p_tag.find_next_sibling())\n",
    "print('-- 모든 다음 형제 노드 --')\n",
    "print(p_tag.find_next_siblings())\n",
    "print('-- 바로 이전 형제 노드 --')\n",
    "print(p_tag.find_previous_sibling())\n",
    "print('-- 모든 이전 형제 노드 --')\n",
    "print(p_tag.find_previous_siblings())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76c73236-52e8-48e2-8ac4-f24f137442d0",
   "metadata": {},
   "source": [
    "## 3.7 검색 : find()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b529045-5c38-4b0f-8ed7-9db01e17e082",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "response = requests.get('https://www.naver.com')\n",
    "soup = BeautifulSoup(response.text, 'lxml')\n",
    "print(soup.find('title'))\n",
    "print(soup.find('a'))\n",
    "print(soup.find(id='search')) #id속성의 값이 search인 정보를 가져옴, soup.find(attrs={'id:'search'})와 동일"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c586213-680e-4f76-ba77-069272a9ee57",
   "metadata": {},
   "source": [
    "## 3.8검색 : find_all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6b3be55e-1e3b-499d-9100-0356935e1170",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27\n",
      "[<a href=\"#topAsideButton\"><span>상단영역 바로가기</span></a>, <a href=\"#shortcutArea\"><span>서비스 메뉴 바로가기</span></a>, <a href=\"#newsstand\"><span>새소식 블록 바로가기</span></a>, <a href=\"#shopping\"><span>쇼핑 블록 바로가기</span></a>, <a href=\"#feed\"><span>관심사 블록 바로가기</span></a>, <a href=\"#account\"><span>MY 영역 바로가기</span></a>, <a href=\"#widgetboard\"><span>위젯 보드 바로가기</span></a>, <a href=\"#viewSetting\"><span>보기 설정 바로가기</span></a>, <a aria-pressed=\"false\" class=\"item _delAll\" href=\"#\" role=\"button\">전체삭제</a>, <a class=\"kwd_help\" data-clk=\"sly.help\" href=\"https://help.naver.com/alias/search/word/word_35.naver\" target=\"_blank\">도움말</a>, <a class=\"kwd_help\" data-clk=\"sly.help\" href=\"https://help.naver.com/alias/search/word/word_35.naver\" target=\"_blank\">도움말</a>, <a class=\"close _keywordOnOff\" href=\"#\">자동저장 끄기</a>, <a data-clk=\"sly.help\" href=\"https://help.naver.com/alias/search/word/word_35.naver\" target=\"_blank\">도움말</a>, <a class=\"close _close\" href=\"#\">닫기</a>, <a aria-pressed=\"false\" class=\"btn_help _tg_btn\" href=\"#\" role=\"button\"><i class=\"imgsvg ico_alert\">이 정보가 표시된 이유</i></a>, <a class=\"btn_close _tg_btn\" href=\"#\" role=\"button\"><i class=\"imgsvg ico_close\">레이어 닫기</i></a>, <a class=\"link _alert_link\" href=\"#\" target=\"_blank\">자세히보기</a>, <a class=\"link_dsc\" data-clk=\"sug.cxhelp\" href=\"https://help.naver.com/alias/search/word/word_16.naver\" target=\"_blank\">관심사를 반영한 컨텍스트 자동완성<i class=\"imgsvg ico_help\">도움말</i></a>, <a aria-pressed=\"false\" class=\"bt_switch active _plus_btn\" href=\"#\" role=\"button\"><i class=\"imgsvg ico_option\">컨텍스트 자동완성</i></a>, <a class=\"link_view\" data-clk=\"sug.cxlink\" href=\"https://help.naver.com/alias/search/word/word_16.naver\" target=\"_blank\">자세히 보기</a>, <a class=\"link_view\" data-clk=\"sug.cxlink\" href=\"https://help.naver.com/support/alias/search/word/word_16.naver\" target=\"_blank\">자세히 보기</a>, <a class=\"btn btn_login\" data-clk=\"sug.cxlogin\" href=\"https://nid.naver.com/nidlogin.login\"><i class=\"imgsvg ico_naver\">네이버</i>로그인</a>, <a class=\"btn_close _plus_layer_close\" href=\"#\" role=\"button\"><i class=\"imgsvg ico_close\">컨텍스트 자동완성 레이어 닫기</i></a>, <a class=\"close _suggestOnOff\" href=\"#\">자동완성 끄기</a>, <a data-clk=\"sug.help\" href=\"https://help.naver.com/alias/search/word/word_17.naver\" target=\"_blank\">도움말</a>, <a class=\"report\" data-clk=\"sug.report\" href=\"https://help.naver.com/alias/search/word/word_18.naver\" target=\"_blank\">신고</a>, <a class=\"close _close\" href=\"#\">닫기</a>]\n"
     ]
    }
   ],
   "source": [
    "a_tags = soup.find_all('a')\n",
    "print(len(a_tags))\n",
    "print(a_tags)\n",
    "#a_tags = soup.find_all('a', limit = 2) 가장 처음 만나는 두개의 a 태그"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f630f944-dcbd-492f-bb0f-3843019fbb67",
   "metadata": {},
   "source": [
    "[실습] 네이버 뉴스 페이지에서 언론사 목록 가져오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0207a324-9a1d-4ca7-90f8-752814fbf383",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<h4 class=\"channel\">서울경제<span class=\"datetime\">04월 05일 10:19</span></h4>\n",
      "['서울경제', <span class=\"datetime\">04월 05일 10:19</span>]\n",
      "['서울경제', '주간조선', '경향신문', '뉴시스', '대전일보', '전주MBC', '채널A', '코리아중앙데일리', 'MBC', '헬스조선']\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "res = requests.get('https://news.naver.com')\n",
    "soup = BeautifulSoup(res.text, 'lxml')\n",
    "result = soup.find_all('h4', attrs={'class':'channel'})\n",
    "#print(len(result))\n",
    "print(result[0]) #태그를 없애고 텍스트 값만 읽어오고 싶으면 print(result[0].get_text()) 또는 print(result[0].text)이용\n",
    "\n",
    "print(list(result[0].children))\n",
    "#['부산일보', <span class=\"datetime\">04월 05일 09:52</span>]\n",
    "\n",
    "press_list = [ list(tag.children)[0] for tag in result]\n",
    "print(press_list[:10])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cb4b2895-14cc-4665-bca5-f4381764b6ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['서울경제', '주간조선', '경향신문', '뉴시스', '대전일보', '전주MBC', '채널A', '코리아중앙데일리', 'MBC', '헬스조선']\n"
     ]
    }
   ],
   "source": [
    "res = requests.get('https://news.naver.com')\n",
    "soup = BeautifulSoup(res.text, 'lxml')\n",
    "result = soup.find_all('div', attrs={'class':'cjs_age_name'})\n",
    "print(press_list[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b24843c-b168-4cb6-9e60-4469161a1c3d",
   "metadata": {},
   "source": [
    "## 3.9 검색 : select_one(), select()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a2f7f52e-9e30-40a4-b67f-596a9cccfa3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<a class=\"show\" href=\"/page/KITA_MAIN\">KITA 무역아카데미</a>\n",
      "220\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "res = requests.get('http://www.tradecampus.com')\n",
    "soup = BeautifulSoup(res.text, 'html.parser')\n",
    "\n",
    "print(soup.select_one('div > a'))\n",
    "result = soup.select('div a')\n",
    "print(len(result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8d34d65e-a87a-4e63-b049-b701883b4832",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<h3 class=\"tit\">공지사항</h3>\n",
      "공지사항\n"
     ]
    }
   ],
   "source": [
    "print(soup.select_one('body > div > div.wrapper.main_page > div.renew_main > div.col-12 > div > div.renew_main_notice > div > div > h3'))\n",
    "\n",
    "#텍스트 값만 읽어오고 싶을때\n",
    "print(soup.select_one('body > div > div.wrapper.main_page > div.renew_main > div.col-12 > div > div.renew_main_notice > div > div > h3').text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b5ddf920-b235-46de-b39f-38626cf755ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<a href=\"/page/user_academy_service_notice?post_seq=20424\">제31기 수출입기업 영업이익의 보전을 위한 원스톱 환리스크관리 개강(3/21)</a>]\n",
      "[<a href=\"/page/user_academy_service_notice?post_seq=20506\">2024년 무역아카데미 주요강좌 안내</a>, <a href=\"/page/user_academy_service_notice?post_seq=20424\">제31기 수출입기업 영업이익의 보전을 위한 원스톱 환리스크관리 개강(3/21)</a>, <a href=\"/page/user_academy_service_notice?post_seq=20413\">관세사의 FTA 활용꿀팁 전수! e러닝 안내(원산지관리전담자 교육점수 인정)</a>]\n",
      "2024년 무역아카데미 주요강좌 안내\n"
     ]
    }
   ],
   "source": [
    "#tradecampus.com 메인 페이지 공지사항 두번째 항목 선택\n",
    "notice = soup.select('body > div > div.wrapper.main_page > div.renew_main > div.col-12 > div > div.renew_main_notice > div > ul > li:nth-child(2) > p > a') \n",
    "print(notice)\n",
    "\n",
    "#:nth-child(#)을 지우면 해당 요소(element)의 모든 요소를 가져온다\n",
    "notice = soup.select('body > div > div.wrapper.main_page > div.renew_main > div.col-12 > div > div.renew_main_notice > div > ul > li > p > a')\n",
    "print(notice) #전체목록 가져오기\n",
    "\n",
    "notice = soup.select('body > div > div.wrapper.main_page > div.renew_main > div.col-12 > div > div.renew_main_notice > div > ul > li > p > a')\n",
    "print(notice[0].text)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "576bb861-b8b1-41dd-ba4f-ce9052b0a49a",
   "metadata": {},
   "source": [
    "## 3.10 텍스트 가져오기 : text, get_tesxt()\n",
    "-  검색 결과에서 태그를 제외한 텍스트만 추출"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "596f2ffd-16ce-4296-8110-531084815411",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "고객센터\n",
      "\n",
      "\n",
      "오프라인 교육, e러닝\n",
      "02-6000-5378/5379\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "운영시간\n",
      "평일 09:00~18:00 (주말/공휴일 : 휴무)\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#고객 센터 영역 텍스트 가져오기\n",
    "tag = soup.find('div', attrs={'class':'serviceInfo'})\n",
    "#print(tag)\n",
    "print(tag.get_text())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "316f198f-3f5d-496e-8d19-d9b88ee6c747",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/weven_template_repository/theme/KITAAC/1/resource/img/ico_sns_facebook.png\n",
      "/weven_template_repository/theme/KITAAC/1/resource/img/ico_sns_facebook.png\n"
     ]
    }
   ],
   "source": [
    "tag = soup.find('img', attrs = {'class':'mobile_icon black'})\n",
    "print(tag['src'])\n",
    "print(tag.get('src'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02a61ff9-1284-4265-8865-97c879240d8a",
   "metadata": {},
   "source": [
    "## 3.11 텍스트 가져오기:string\n",
    "- 검색 결과에서 **태그 안에 또 다른 태그가 없는 경우** 해당 내용을 출력"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "74fb2832-f5ad-49a7-b616-49a86cc79a88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "오프라인 교육, e러닝\n"
     ]
    }
   ],
   "source": [
    "tag = soup.find('div', attrs={'class':'serviceInfo'})\n",
    "tag = tag.find('span')\n",
    "print(tag.string)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c75a0fd-df11-4d9c-9eb2-eb4f97c3035f",
   "metadata": {},
   "source": [
    "[실습] 네이버 웹툰 제목 가져오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b10b9f6-3600-462d-86b5-c7e48f46c093",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!pip install selenium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "596b2707-8102-4415-9546-0e11b9eb60bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting webdriver_manager\n",
      "  Downloading webdriver_manager-4.0.1-py2.py3-none-any.whl.metadata (12 kB)\n",
      "Requirement already satisfied: requests in c:\\users\\user\\anaconda3\\lib\\site-packages (from webdriver_manager) (2.31.0)\n",
      "Requirement already satisfied: python-dotenv in c:\\users\\user\\anaconda3\\lib\\site-packages (from webdriver_manager) (0.21.0)\n",
      "Requirement already satisfied: packaging in c:\\users\\user\\anaconda3\\lib\\site-packages (from webdriver_manager) (23.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\user\\anaconda3\\lib\\site-packages (from requests->webdriver_manager) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\user\\anaconda3\\lib\\site-packages (from requests->webdriver_manager) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\user\\anaconda3\\lib\\site-packages (from requests->webdriver_manager) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\user\\anaconda3\\lib\\site-packages (from requests->webdriver_manager) (2024.2.2)\n",
      "Downloading webdriver_manager-4.0.1-py2.py3-none-any.whl (27 kB)\n",
      "Installing collected packages: webdriver_manager\n",
      "Successfully installed webdriver_manager-4.0.1\n"
     ]
    }
   ],
   "source": [
    "!pip install webdriver_manager"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "3784b9b6-e37c-4e50-b75e-d83fd9e64a57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "URL = 'https://comic.naver.com/webtoon'\n",
    "res = requests.get(URL)\n",
    "soup = BeautifulSoup(res.text, 'lxml')\n",
    "\n",
    "#아래 두가지 방법으로는 찾을 수가 없다 > selenium 이용\n",
    "#webtoon_titles = soup.find_all('span',attrs = {'class':'ContentTitle__title--e3qXt'})\n",
    "#print(len(webtoon_titles))\n",
    "\n",
    "#webtoon_titles = soup.select_one('#container > div.component_wrap.type2 > div.WeekdayMainView__daily_all_wrap--UvRFc > div:nth-child(1) > ul > li:nth-child(1) > div > a > span > span')\n",
    "#print(webtoon_titles)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7912e07d-e816-4bea-98bc-ee5d2f01dd63",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7\n",
      "==== 월요 웹툰====\n",
      "뷰티풀 군바리\n",
      "참교육\n",
      "백수세끼\n",
      "신의 탑\n",
      "왕과의 야행\n",
      "장씨세가 호위무사\n",
      "퀘스트지상주의\n",
      "윈드브레이커\n",
      "소녀의 세계\n",
      "신화급 귀속 아이템을 손에 넣었다\n",
      "버림받은 왕녀의 은밀한 침실\n",
      "팔이피플\n",
      "절대검감\n",
      "별난식당\n",
      "귀촌리\n",
      "환생천마\n",
      "회귀한 공작가의 막내도련님은 암살자\n",
      "우아한 욕망\n",
      "어린이집 다니는 구나\n",
      "만렙돌파\n",
      "진주\n",
      "수상한 다이어트 클럽\n",
      "여고생이 신인데 나만 괴롭힘\n",
      "마왕을 그만둔 이유\n",
      "북부 공작님을 유혹하겠습니다\n",
      "개같이 탈출\n",
      "악당 가족이 독립을 반대한다\n",
      "녹빛자정의 연인\n",
      "인섹터\n",
      "히어로메이커\n",
      "제왕\n",
      "더블클릭\n",
      "토마토가 돼라!\n",
      "리턴 투 플레이어\n",
      "칼가는 소녀\n",
      "영업 천재가 되었다\n",
      "좀비묵시록 82-08\n",
      "미친 재능의 플레이어\n",
      "막장 악녀\n",
      "결혼생활 그림일기\n",
      "루루라라 우리네 인생\n",
      "아슈타르테\n",
      "찔레꽃 그늘 아래\n",
      "파운더\n",
      "함부로 친절하지 말라\n",
      "보스리턴\n",
      "오빠집이 비어서\n",
      "사랑, 그거 어떻게 하는 건데\n",
      "헬크래프트\n",
      "시한부의 아이까지 뺏으려 합니다\n",
      "꿈의 기업\n",
      "공녀님의 꽃밭에는 그들이 산다\n",
      "내가 왜 킬러?!\n",
      "엘프\n",
      "악녀교실\n",
      "제국 제일의 상속녀가 되었습니다\n",
      "K학원 생존기\n",
      "쥴리에타의 드레스 업\n",
      "영앤리치가 아니야!\n",
      "반려짐승\n",
      "달로 만든 아이\n",
      "사이다걸\n",
      "두 번째 삶은 힐링라이프?\n",
      "집사, 주세요!\n",
      "백호랑\n",
      "찌질하지만 로맨스는 하고 싶어\n",
      "마이너스의 손\n",
      "학식의 꿈\n",
      "프로페서\n",
      "다육이는 잘 자란다\n",
      "최후의 금빛아이\n",
      "고백어택\n",
      "어쌔신 크리드 - 잊혀진 사원\n",
      "컨트롤X\n",
      "날 먹는 건 금지양!\n",
      "나의 보이소프렌드\n",
      "역주행!\n",
      "포스트 팬데믹\n",
      "선빵필승!\n",
      "주작연애\n",
      "티엔다비스 - 완벽한 구원을 위하여\n",
      "처음을 줄게!\n",
      "오늘의 일기예보\n",
      "버그이터\n",
      "러브 똘츄얼리\n",
      "트리거\n",
      "악취해결사\n",
      "어느날 짝남에게 공작님이 빙의했다\n",
      "\n",
      "==== 화요 웹툰====\n",
      "좋아? 죽어!\n",
      "김부장\n",
      "마음의소리2\n",
      "서울 자가에 대기업 다니는 김 부장 이야기\n",
      "내가 키운 S급들\n",
      "마루는 강쥐\n",
      "괴력 난신\n",
      "유부 감자\n",
      "사신소년\n",
      "멸망 이후의 세계\n",
      "한림체육관\n",
      "천마는 평범하게 살 수 없다\n",
      "하루만 네가 되고 싶어\n",
      "욕망일기Deep\n",
      "집이 없어\n",
      "이섭의 연애\n",
      "궤짝\n",
      "유사연애\n",
      "신입사원 김철수\n",
      "성검전설\n",
      "하북팽가 막내아들\n",
      "초인의 게임\n",
      "피부과 만렙남\n",
      "불 빌려드릴까요?\n",
      "삼국지톡\n",
      "백씨세가 시한부 공자\n",
      "사변괴담\n",
      "저 그런 인재 아닙니다\n",
      "포 더 퀸덤\n",
      "도태교실\n",
      "놓지마 정신줄 시즌3\n",
      "원주민 공포만화\n",
      "염라강림\n",
      "사람의 탈\n",
      "우리 집 고양이 보고 갈래?\n",
      "일홀도\n",
      "못 잡아먹어서 안달\n",
      "이상형\n",
      "올가미\n",
      "아카데미 플레이어를 죽였다\n",
      "윌유메리미\n",
      "신과함께 돌아온 기사왕님\n",
      "랜덤채팅의 그녀!\n",
      "시체기사 군터\n",
      "내 남편의 정부에게\n",
      "사리네 보석함\n",
      "연우의 순정\n",
      "하우스키퍼\n",
      "로잘린 보가트\n",
      "약 파는 황태자\n",
      "빌런투킬\n",
      "헥토파스칼\n",
      "은주의 방 2~3부\n",
      "체탐자\n",
      "1331\n",
      "왕게임\n",
      "반대로 끌리는 사이\n",
      "웅크\n",
      "개같은 아빠\n",
      "에이머\n",
      "파도의 포말\n",
      "오아뉴-멱살 한번 잡힙시다\n",
      "빛나는 나나나나\n",
      "집착남주의 전부인이 되었습니다\n",
      "그냥 선생님\n",
      "맹수 사용 설명서\n",
      "형사본색\n",
      "아이즈\n",
      "해골협객\n",
      "뜻밖의 청혼\n",
      "암호는 002!\n",
      "흑역사 어게인\n",
      "배드 엔딩 메이커\n",
      "친애하는 연서\n",
      "환수왕\n",
      "폭군의 심장을 쥐었다\n",
      "헬스x로맨스\n",
      "거짓말의 뉘앙스\n",
      "무원야담\n",
      "랜덤타겟\n",
      "착한 여자 안선해\n",
      "주인님을 잡아먹는 방법\n",
      "제로게임\n",
      "우투리: THE LEGACY\n",
      "미워할 거야\n",
      "붉은 이정표\n",
      "윗집 그 남자\n",
      "렌탈히어로\n",
      "필리아로제 - 가시왕관의 예언\n",
      "원포인트\n",
      "시한부 황후의 나쁜 짓\n",
      "동경과 거짓말\n",
      "자매의 사생활\n",
      "돌격! 용마치킨\n",
      "죽었던 너와 다시 시작하기\n",
      "왕자님 짠내밥상\n",
      "아, 연애하고 싶다\n",
      "대리게임\n",
      "그 남학생에게 고백하지 마십시오\n",
      "\n",
      "==== 수요 웹툰====\n",
      "화산귀환\n",
      "마음의소리(였던 것)\n",
      "전지적 독자 시점\n",
      "무직백수 계백순\n",
      "백XX\n",
      "조조코믹스\n",
      "진돌히디만화\n",
      "헬퍼 2 : 킬베로스\n",
      "66666년 만에 환생한 흑마법사\n",
      "미래의 골동품 가게\n",
      "일렉시드\n",
      "운명을 보는 회사원\n",
      "캐슬2:만인지상\n",
      "1등급 싸움과외\n",
      "격기3반\n",
      "칼에 취한 밤을 걷다\n",
      "왕따가 격투기를 너무 잘함\n",
      "어린이집 다니는 구나\n",
      "나쁜사람\n",
      "튜토리얼 탑의 고인물\n",
      "무림서부\n",
      "별을 품은 소드마스터\n",
      "기묘한 만화\n",
      "흔한 빙의물인 줄 알았다\n",
      "쌉초의 난\n",
      "중간에서 만나\n",
      "마른 가지에 바람처럼\n",
      "강철을 먹는 플레이어\n",
      "베이비 폭군\n",
      "악의 등교\n",
      "쓰레기는 쓰레기통에!\n",
      "남사친의 법칙\n",
      "어느 마법사의 식당\n",
      "사천당가의 검신급 소가주가 되었다\n",
      "사상최강\n",
      "울어 봐, 빌어도 좋고\n",
      "인과관계\n",
      "마님이네 미국 시골집 이야기\n",
      "어린 상사\n",
      "여명의 등불\n",
      "안녕, 나의 수집\n",
      "나의 신은 욕망꾸러기\n",
      "닥터앤닥터 병원일기\n",
      "언덕 위의 제임스\n",
      "망치하르방\n",
      "칼부림\n",
      "결혼 시뮬레이션\n",
      "판타지 여동생!\n",
      "귀비나리\n",
      "두 번 사는 프로듀서\n",
      "마침표의 유예기간\n",
      "겨울 정원의 하와르\n",
      "수요웹툰의 나강림\n",
      "뽀대작렬\n",
      "수인 보호소에서 남주를 입양해 버렸다\n",
      "괴물공작의 딸\n",
      "변방의 외노자\n",
      "삼덕천하\n",
      "좀간\n",
      "에브리띵 이즈 파인\n",
      "돌아온 쿠쿠짱\n",
      "강아지는 멍멍하고 짖지 않아!\n",
      "하렘의 남자들\n",
      "신입은 낮져밤이\n",
      "나를 낳아줘\n",
      "쇼윈도 탈출\n",
      "연애일기\n",
      "짝사랑은 결혼으로 끝나지 않는다\n",
      "미시령\n",
      "영웅&마왕&악당\n",
      "누가 나를 죽였을까\n",
      "산타 스카우트\n",
      "말숙이를 부탁해\n",
      "선배는 나빠요!\n",
      "두꺼비집\n",
      "그 남자의 은밀한 하루\n",
      "용한소녀\n",
      "더 베이비시터\n",
      "나랑 해요\n",
      "로어 올림푸스\n",
      "고백하면 끝나는 만화\n",
      "그때 그 채영민\n",
      "멸종위기종인간\n",
      "두 마리를 위한 뜰\n",
      "사생돌\n",
      "어느 백작 영애의 이중생활\n",
      "반짝반짝 작은 눈\n",
      "범상찮은 밤\n",
      "나의 계절\n",
      "49번 남았습니다, 스승님!\n",
      "히어로 더 맥시멈\n",
      "우리의 연애일지\n",
      "이런 미친 엔딩\n",
      "연애고수\n",
      "사랑아, 영원해!\n",
      "솔그린\n",
      "수플레 팬 케이크\n",
      "\n",
      "==== 목요 웹툰====\n",
      "나노마신\n",
      "촉법소년\n",
      "재벌집 막내아들\n",
      "순결을 그대에게\n",
      "천마육성\n",
      "할배무사와 지존 손녀\n",
      "뮤즈 온 유명\n",
      "회귀한 천재 헌터의 슬기로운 청소생활\n",
      "마도귀환록\n",
      "정글쥬스\n",
      "소꿉친구 컴플렉스\n",
      "나 혼자 네크로맨서\n",
      "사내연애 사절!\n",
      "버려진 나의 최애를 위하여\n",
      "내향남녀\n",
      "게임 속 바바리안으로 살아남기\n",
      "룸비니\n",
      "피부과 만렙남\n",
      "흔한햄\n",
      "네이처맨\n",
      "가족같은 XX\n",
      "비서 일탈\n",
      "현실퀘스트\n",
      "첫날밤을 보낸 그 악녀를 찾습니다\n",
      "개구리 인간\n",
      "VS\n",
      "순수한 동거생활\n",
      "시한부 천재 암흑기사\n",
      "보스였음\n",
      "마왕까지 한 걸음\n",
      "최강전설 강해효\n",
      "일립예고 학생들\n",
      "사형집행관\n",
      "규격 외 혈통 천재\n",
      "쿠베라\n",
      "기자매\n",
      "게임 최강 트롤러\n",
      "불편한 관계\n",
      "오만의 시대\n",
      "두 번째 딸로 태어났습니다\n",
      "마법사랑해\n",
      "꽃만 키우는데 너무강함\n",
      "루루라라 우리네 인생\n",
      "서울밤피어\n",
      "흑막 여주가 날 새엄마로 만들려고 해\n",
      "오, 친애하는 숙적\n",
      "미리보기\n",
      "관계중독\n",
      "썩은 핑크의 법칙\n",
      "SPT - 박쥐의 시간\n",
      "삼이는 재생한다\n",
      "부부의 의무를 원하신다면\n",
      "검은 인어\n",
      "이러면 안 돼요, 전하!\n",
      "히든클래스 중력자로 최강을 노린다\n",
      "돈내놔\n",
      "국세청 망나니\n",
      "만물의 영장\n",
      "이상한 변호사 우영우\n",
      "당신의 그림자를 그만두었을 때\n",
      "이세계 탈출\n",
      "그 악룡은 무엇을 위해 사는가\n",
      "2차전직 스킵용사\n",
      "쌍둥이 영애가 남장을 하는 이유\n",
      "웨폰 크리에이터\n",
      "내가 사랑한 물고기\n",
      "엔딩, 바꿔보려합니다\n",
      "영광의 해일로\n",
      "황제사냥\n",
      "베니루 BAENIRU\n",
      "학생만 하면 안 될까요?\n",
      "35cm\n",
      "너와 XX\n",
      "더티드레스\n",
      "카루나\n",
      "보물과 괴물의 도시\n",
      "여친을 찾아서\n",
      "유월의 소한\n",
      "첫사랑, 두 번째\n",
      "일진만화에서 살아남기\n",
      "권리행사자\n",
      "사랑하는 여배우들\n",
      "올빼미와 여름 하늘\n",
      "괴물의 바다\n",
      "잘못된 연애\n",
      "미라주\n",
      "사기 친 공작님을 유혹해버렸다\n",
      "\n",
      "==== 금요 웹툰====\n",
      "좋아? 죽어!\n",
      "외모지상주의\n",
      "광마회귀\n",
      "나 혼자 만렙 뉴비\n",
      "역대급 영지 설계사\n",
      "재혼 황후\n",
      "유부 감자\n",
      "상남자\n",
      "개를 낳았다\n",
      "언니, 이번 생엔 내가 왕비야\n",
      "열렙전사 3부\n",
      "1초\n",
      "낙향문사전\n",
      "나 혼자 탑에서 농사\n",
      "천하제일 대사형\n",
      "A.I. 닥터\n",
      "죽지 않으려면\n",
      "전남편의 미친개를 길들였다\n",
      "가장 썩은 것을 줄게\n",
      "서울역 드루이드\n",
      "문제적 왕자님\n",
      "연애의 기록\n",
      "삼국지톡\n",
      "여동생은 오늘 밤 나를 간택한다\n",
      "브레이커 : 이터널 포스\n",
      "말년용사\n",
      "약탈 신부\n",
      "그렇게 물거품이 되어도\n",
      "히어로 킬러\n",
      "펜홀더\n",
      "대신 살쪄주는 여자\n",
      "더 게이머\n",
      "새동네\n",
      "뫼신 사냥꾼\n",
      "사신\n",
      "미친 후작을 길들이고 말았다\n",
      "플레이어\n",
      "온리호프\n",
      "벌집\n",
      "암살청과\n",
      "도깨비의 밤\n",
      "아카데미에서 살아남기\n",
      "그 기사가 레이디로 사는 법\n",
      "도무지 그애는\n",
      "대위님! 이번 전쟁터는 이곳인가요?\n",
      "흑요석의 신부\n",
      "소름일기\n",
      "공동급식구역\n",
      "뼈왕\n",
      "소희 훔치기\n",
      "킬 더 드래곤\n",
      "웅크\n",
      "로또 황녀님\n",
      "소곤소곤2\n",
      "무제인간\n",
      "그냥 선생님\n",
      "세자와 세자빈의 계약혼인전\n",
      "야수라는 공작에게 시집왔는데\n",
      "복수 법률사무소\n",
      "그 남자의 정원\n",
      "후덜덜덜 남극전자\n",
      "여름의 너에게\n",
      "평화식당\n",
      "센스제로\n",
      "천재 배우의 아우라Aura\n",
      "사냥개의 회귀본능\n",
      "몽홀\n",
      "악마라고 불러다오\n",
      "걔의 질투\n",
      "룸9\n",
      "달이 없는 나라\n",
      "신컨의 원 코인 클리어\n",
      "솔트앤페퍼\n",
      "그거 사랑 아니야\n",
      "재앙의 날\n",
      "멜빈이 그들에게 남긴 것\n",
      "당신의 사랑\n",
      "3분의 1이 없어도\n",
      "뜨거운 홍차\n",
      "메소드 연기법\n",
      "스토커의 하루\n",
      "미드우트\n",
      "괴물 의상실\n",
      "오!너의 리스크\n",
      "우리 무슨 사이야?\n",
      "우리는 후라이족\n",
      "백년게임\n",
      "합법해적 파르페\n",
      "드래곤의 심장을 가지고 있습니다\n",
      "콜미로맨틱\n",
      "유주의 우주\n",
      "기억해줘\n",
      "애증화음\n",
      "하는 사이\n",
      "\n",
      "==== 토요 웹툰====\n",
      "개꿈\n",
      "99강화나무몽둥이\n",
      "조조코믹스\n",
      "초인의 시대\n",
      "마도전생기\n",
      "비질란테 2부\n",
      "킬러 배드로\n",
      "인생존망2\n",
      "아홉수 우리들\n",
      "어글리후드\n",
      "욕망일기Deep\n",
      "세레나\n",
      "망나니 소교주로 환생했다\n",
      "킬러경찰\n",
      "흔한햄\n",
      "디펜스 게임의 폭군이 되었다\n",
      "얼짱시대\n",
      "아이 하나\n",
      "신입사원 강 회장\n",
      "쌉초의 난\n",
      "나를 바꿔줘\n",
      "나이트런\n",
      "짜장 한 그릇에 제갈세가 데릴사위\n",
      "황제의 검\n",
      "놓지마 정신줄 시즌3\n",
      "왕의 힘으로 회귀한다\n",
      "소공녀 민트\n",
      "야매 힐러로 사는 법\n",
      "마님이네 미국 시골집 이야기\n",
      "윌유메리미\n",
      "나를 미워하던 남편이 기억을 잃었다\n",
      "사랑하는 나의 억압자\n",
      "플레이어가 과거를 숨김\n",
      "대충 캠퍼스로맨스임\n",
      "멸망한 세계의 취사병\n",
      "탑아이돌의 막내 멤버가 되었다\n",
      "예명여고\n",
      "민간인 통제구역 - 일급기밀\n",
      "같은 학교 친구\n",
      "망치하르방\n",
      "부패의 사제\n",
      "회귀자의 은퇴 라이프\n",
      "멸망한 가문의 회귀자\n",
      "탑코너\n",
      "더 해머\n",
      "흑화한 노예남을 길들였다\n",
      "홍시는 날 좋아해!\n",
      "천 살 연하 황제가 집착한다\n",
      "스쿨 오브 스트릿\n",
      "다비, 아찔하게 흐르는\n",
      "괴양이\n",
      "전생연분\n",
      "이세계 강셰프\n",
      "용사참수인\n",
      "돌아온 쿠쿠짱\n",
      "천마의 후손이 되었다\n",
      "묘약마녀\n",
      "좀비X슬래셔\n",
      "저무는 해, 시린 눈\n",
      "공유몽\n",
      "완벽한 부부는 없다\n",
      "이계진입 리로디드\n",
      "K학원 생존기\n",
      "첫사랑은 헤이트\n",
      "지옥2:부활자\n",
      "수호소녀\n",
      "시한부 기사가 되었다\n",
      "당신이 나를 믿으신다면\n",
      "마법사가 죽음을 맞이하는 방법\n",
      "사기캐\n",
      "사서고생!\n",
      "복수를 위한 결혼동맹\n",
      "용두사망 소설 속의 악녀가 되었다\n",
      "아사\n",
      "위험한 거짓말\n",
      "S.K.T(Swallow Knights Tales)\n",
      "동그란 그녀와 소심한 그 남자\n",
      "괴물의 순결한 심장\n",
      "박제하는 시간\n",
      "너에게로 중독\n",
      "연애 생각은 없지만\n",
      "마이 데몬\n",
      "X의 목줄을 쥐는 법\n",
      "솔직하게 말해줘!\n",
      "이매망량\n",
      "애구애구\n",
      "왕세자 입학도\n",
      "동녘과 백야\n",
      "오후가 멈추도록\n",
      "데이팅 캣\n",
      "궤도의 아이들\n",
      "먹지마세요\n",
      "아침을 지나 밤으로\n",
      "너나 나나\n",
      "멸망으로 시작하는! 근미래 생존법\n",
      "\n",
      "==== 일요 웹툰====\n",
      "무직백수 계백순\n",
      "입학용병\n",
      "기기괴괴2\n",
      "별이삼샵\n",
      "시월드가 내게 집착한다\n",
      "천화서고 대공자\n",
      "나 혼자 특성빨로 무한 성장\n",
      "하자인간\n",
      "먹뀌싸\n",
      "수희0(tngmlek0)\n",
      "아카데미의 천재칼잡이\n",
      "날 닮은 아이\n",
      "이발소 밑 게임가게\n",
      "고수, 후궁으로 깨어나다\n",
      "분신으로 자동사냥\n",
      "무능력자\n",
      "부동산이 없는 자에게 치명적인\n",
      "청춘계시록\n",
      "아카데미에 위장취업당했다\n",
      "폰투스 : 극야2\n",
      "소녀재판\n",
      "죽거나 혹은 사랑에 빠지거나\n",
      "위닝샷!\n",
      "혼자 다 해 먹는 천재 암살자\n",
      "안녕, 나의 수집\n",
      "내일\n",
      "장풍전\n",
      "피폐물 남주의 엄마가 되었다\n",
      "마법스크롤 상인 지오\n",
      "그 머리 긴 선배, 이름이 뭐더라?\n",
      "망돌의 사생\n",
      "환생좌\n",
      "약빨이 신선함\n",
      "무진\n",
      "홍끼의 메소포타미아 신화\n",
      "사랑받는 시집살이\n",
      "무서운게 딱좋아!\n",
      "칼끝에 입술\n",
      "경자 전성시대\n",
      "최후의 모험가\n",
      "상사불상사\n",
      "허리케인 공주님\n",
      "악녀는 조용히 살고 싶을 뿐인데!\n",
      "이웃집 연하\n",
      "서과장은 산재처리 됐을까\n",
      "용사보다 너무 강해서 힘을 숨김\n",
      "펀치드렁커드\n",
      "오로지 너를 이기고 싶어\n",
      "망겜의 시체줍는 천재전사\n",
      "로봇소녀 노이도\n",
      "찐한 고백\n",
      "재벌의 품격\n",
      "강아지는 멍멍하고 짖지 않아!\n",
      "밤마다 남편이 바뀐다\n",
      "내게 종말은 게임이다\n",
      "최고의 뿔소라\n",
      "연애일기\n",
      "다크 판타지 속 성기사\n",
      "팔문의 옥\n",
      "신혼부부 생활 백서\n",
      "홍 의관의 은밀한 비밀\n",
      "내곁엔 없을까\n",
      "불완전 신데렐라물\n",
      "여우애담\n",
      "오!단군\n",
      "첫날밤만 세 번째\n",
      "랑데뷰\n",
      "아무래도 결혼을 잘못한 것 같다\n",
      "마왕의 고백\n",
      "여신님의 호랑이 공략법\n",
      "神장산범\n",
      "사장님이 미쳤어요\n",
      "미친 황제가 나를 안을 때\n",
      "키스는 자기 전에\n",
      "죽고 싶습니다\n",
      "패션쇼\n",
      "밤필드의 아이들 by DARK MOON\n",
      "완벽한 파트너\n",
      "추락한 곳은 낙원\n",
      "데빌샷\n",
      "갑!자기 건물주\n",
      "아빠는 버츄얼 아이돌\n",
      "백설을 위하여\n",
      "킬링킬러\n",
      "숲속의 대표님\n",
      "포크&나이프\n",
      "주인공의 주식을 팝니다\n",
      "손 잡은 사이\n",
      "마섹남 - 마술하는 섹시한 남자\n",
      "황금의 세계를 너에게\n",
      "블러드 리벤저\n",
      "망돌리부트\n",
      "노래 못 하는 남자\n",
      "급발진 로맨스\n",
      "내가 만든 이세계\n",
      "프린키피아\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import time\n",
    "from bs4 import BeautifulSoup\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver import Chrome, ChromeOptions\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "\n",
    "driver = Chrome(service=Service(ChromeDriverManager().install()), options=ChromeOptions())\n",
    "# 위에는 패키지를 동적으로 다운 받아 실행하는 방법\n",
    "\n",
    "URL = 'https://comic.naver.com/webtoon'\n",
    "driver.get(URL)\n",
    "time.sleep(4) # 동적으로 생성되는 페이지의 내용이 완성될 때까지 대기\n",
    "soup = BeautifulSoup(driver.page_source, 'lxml')\n",
    "\n",
    "# 요일별 전체 웹툰 CSS 선택자\n",
    "temp = soup.select_one('#container > div.component_wrap.type2 > div.WeekdayMainView__daily_all_wrap--UvRFc') # '#container' -> '#' = 아이디선택자\n",
    "#print(temp)\n",
    "\n",
    "#요일별 div 태그 검색\n",
    "temp = temp.find_all('div', attrs={'class':'WeekdayMainView__daily_all_item--DnTAH'})\n",
    "print(len(temp))\n",
    "\n",
    "week = ['월', '화', '수','목', '금', '토','일']\n",
    "for i, w in enumerate(temp):\n",
    "    print(f'==== {week[i]}요 웹툰====')\n",
    "    webtoon_list = w.find_all('li', attrs={'class':'DailyListItem__item--LP6_T'})\n",
    "    for webtoon in webtoon_list:\n",
    "        print(webtoon.find('span', attrs={'class':'text'}).text)\n",
    "    print()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37b7b002-1417-4bbf-b793-9f976324b336",
   "metadata": {},
   "source": [
    "[실습] 메가박스 영화정보 사이트에서 영화 포스터 다운로드 하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f97f5d86-2d30-49d6-8b0d-613c3c48b127",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20\n",
      "End\n"
     ]
    }
   ],
   "source": [
    "# 사전 테스트 : 박스오피스 1위 영화 포스터 이미지 가져오기\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.chrome.options import ChromiumOptions\n",
    "from webdriver_manager.chrome import ChromeDriver\n",
    "\n",
    "driver = Chrome(service=Service(ChromeDriverManager().install()),options=ChromeOptions())\n",
    "\n",
    "URL = 'https://www.megabox.co.kr/movie'\n",
    "driver.get(URL)\n",
    "\n",
    "soup = BeautifulSoup(driver.page_source, 'lxml')\n",
    "poster_img = soup.select('#movieList > li > div.movie-list-info > img')\n",
    "print(len(poster_img))\n",
    "poster_img_src = poster_img[0].get('src')\n",
    "\n",
    "import requests\n",
    "res = requests.get(poster_img_src)\n",
    "with open('poster.jpg', 'wb') as f:\n",
    "    f.write(res.content)\n",
    "print('End')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0706cec8-c546-492c-8fe3-46657e6a8986",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver import Chrome, ChromeOptions\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "\n",
    "driver = Chrome(service=Service(ChromeDriverManager().install()), options=ChromeOptions())\n",
    "URL = 'https://www.cgv.co.kr/movies'\n",
    "driver.get(URL)\n",
    "soup = BeautifulSoup(driver.page_source, 'lxml')\n",
    "poster_img = soup.select('#contents > div.wrap-movie-chart > div.sect-movie-chart > ol:nth-child(2) > li:nth-child(1) > div.box-image > a > span > img')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96e9641f-29c4-4683-9592-ad7e588f82ca",
   "metadata": {},
   "source": [
    "[문제] 메가박스 영화 사이트에서 첫 페이지에 있는 모든 영화 포스트 이미지 수집하기\n",
    "- 메가박스 영화 사이트 첫 페이지에 있는 20개의 영화 포스트 이미지 수집\n",
    "- 현재 작업 디렉토리 밑에 'poster_img'폴더가 없는 경우 폴더를 생성한다.(os 패키지 디렉토리 이용)\n",
    "- 저장되는 각 포스터 이미지의 파일이름은 영화 제목으로 한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9346dc34-dba4-4457-8385-63655e1da761",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "폴더 생성 완료\n",
      "1 : https://img.cgv.co.kr/Movie/Thumbnail/Poster/000088/88077/88077_320.jpg\n"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver import Chrome, ChromeOptions\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "import requests\n",
    "\n",
    "driver = Chrome(service=Service(ChromeDriverManager().install()), options=ChromeOptions())\n",
    "URL = 'https://www.megabox.co.kr/movie'\n",
    "driver.get(URL)\n",
    "soup = BeautifulSoup(driver.page_source, 'lxml')\n",
    "\n",
    "# 포스터 이미지를 가지고 있는 모든 img 태그를 검색\n",
    "poster_imgs = soup.find_all('img', attrs={'class':'poster lozad'})\n",
    "# print(len(poster_imgs))\n",
    "\n",
    "# 이미지를 저장할 폴더 생성\n",
    "import os\n",
    "img_dir = './poster_img/' # .은 현재 경로\n",
    "if not os.path.exists(img_dir):\n",
    "    os.mkdir(img_dir)\n",
    "    print('폴더 생성 완료')\n",
    "else:\n",
    "    print('폴더가 존재함')\n",
    "\n",
    "for i, poster in enumerate(poster_img, 1): # 시작값 1 입력함. 디폴트 0\n",
    "    title = poster.get('alt') # 영화 제목 속성 poster[alt]도 가능\n",
    "    img_url = poster.get('src') # 이미지 파일 poster[src]도 가능\n",
    "\n",
    "    print(i, ':', img_url)\n",
    "    img_res = requests.get(img_url)\n",
    "\n",
    "    if ':' in title:\n",
    "        title = title.replace(':',' ')\n",
    "\n",
    "    with open(img_dir+f'[{i}].(title).jpg', 'wb') as f:\n",
    "        f.write(img_res.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3c7872e-6be1-411a-994c-ccf24242e19f",
   "metadata": {},
   "source": [
    "[실습] 네이버 뉴스 사이트에서 경제 관련 언론사별 랭킹뉴스 추출하기\n",
    "- 언론사 이름에 '경제'단어가 포함된 언론사의 랭킹 뉴스만 추출하여 출력한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "81b661ea-e04d-43fe-bd87-e31dfc6ca7a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "등록 언론사 개수: 83\n",
      "언론사: 아시아경제\n",
      "1:\"땅 팔아요, 단 중국인은 사지 마세요\"… '노 차이나' 확산하는 美\n",
      "2:\"만성피로는 소리없는 살인자\"…걸그룹 멤버도 무기한 활동중단\n",
      "3:\"불교가 이렇게 힙할 줄 몰랐다\"…불교박람회 때아닌 흥행몰이\n",
      "4:경치 좋은 곳에서 '숲멍'하고 돈 받는 직업…\"연봉 5천 이상\"\n",
      "5:尹, '이재명 헬기 이송 논란' 부산대병원 권역외상센터 방문…\"전폭적 지원\"\n",
      "\n",
      "언론사: 매일경제\n",
      "1:“손흥민 어쩌나”...토트넘 구단주, 불법 주식거래 미국서 ‘유죄’ 확정\n",
      "2:“가급적 나가지 마세요”…한달치 비 한꺼번에 쏟아진 시드니, 항공편 100여편 취소\n",
      "3:“여성신체 과도하게 드러내더니”…수원 이어 파주서도 무산된 성인페스티벌\n",
      "4:지진 몰아치는데…식당 문열고 택시·기차 정상운영한 비결은 [대만 지진르포]\n",
      "5:명룡대전 무게추 옮긴 3040 … 이재명 53%·원희룡 40%\n",
      "\n",
      "언론사: 서울경제\n",
      "1:항공편 100편 이상 취소에 댐 범람 위험…하루에 한달치 비 퍼부은 '이 나라'\n",
      "2:\"술 취해서 자는 거예요\" 홀로 떠난 男…여관방서 50대女 숨진 채 발견\n",
      "3:58세 할머니 레깅스 입고 손주들 앞서 '이 자세'로 4시간 반 버티다 결국…\n",
      "4:한동훈 \"높은 사전투표율, 우리가 뭉친다는 얘기\"\n",
      "5:기초 수급자로…평생 아껴 모은 전 재산 기부하고 홀로 떠난 할머니 사연에 '눈물이 왈칵'\n",
      "\n",
      "언론사: 한국경제\n",
      "1:대놓고 '조국당' 힘실은 文…\"탈당하라\" 이재명 지지자 분노\n",
      "2:\"수입 얼마나 줄었길래\"…전공의 떠난 대형병원 '파산 위기'\n",
      "3:'성시경 막걸리' 결국 일냈다…주류 전문가들 '감탄'\n",
      "4:암표 잡으려다 아이유 팬 '눈물'…500만원까지 뛴 티켓 어쩌나 [연계소문]\n",
      "5:1억원대 '남편 빚투'…배우 최정원 \"모르는 내용, 별거 상태\"\n",
      "\n",
      "언론사: 헤럴드경제\n",
      "1:“짜장면 한그릇에 배달비 4000원, 이젠 없다” 화들짝 놀란 요기요 눈물의 결단\n",
      "2:“호빵 두 개 붙인 줄 알았다” 조롱받던 사진 속 헤드폰 ‘반전’…새 제품 등장\n",
      "3:[단독] “아! 알리 꼼수에 당했다” 싼맛에 샀다가 환불하면 이용자만 손해…이러다가?\n",
      "4:“아무도 이럴 줄 몰랐다” 설마했는데…충격에 빠진 삼성\n",
      "5:[속보]이스라엘 “구호트럭 오폭 ‘심대한 실수’…하마스로 오인했다”\n",
      "\n",
      "언론사: 한국경제TV\n",
      "1:롯데월드 최초 '통째 대관'…\"영원히 잊지 못해\"\n",
      "2:8.2% 적금 팔아놓고…\"파산 우려되니 해지 좀\"\n",
      "3:입장료 받는 '물의 도시'…\"자고가면 면제\"\n",
      "4:영업익 10배 뛴 삼성전자…\"연간 40조원 가능\"\n",
      "5:GTX 많이 안타는데…주변 집값은 신고가 [부동산플러스]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "URL = 'https://news.naver.com/main/ranking/popularDay.naver'\n",
    "res = requests.get(URL)\n",
    "soup = BeautifulSoup(res.text, 'html.parser')\n",
    "\n",
    "news_list = soup.find_all('div',attrs={'class':'rankingnews_box'})\n",
    "print('등록 언론사 개수:', len(news_list))\n",
    "for news in news_list:\n",
    "    press_title = news.find('strong').text\n",
    "    if '경제' in press_title:\n",
    "        print('언론사:',press_title)\n",
    "        press_news = news.find_all('div',attrs={'class':'list_content'})\n",
    "        for i, ranking_news in enumerate(press_news, 1):\n",
    "            print(f'{i}:{ranking_news.find(\"a\").get_text()}')\n",
    "        print()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1d9df88-a223-467e-a0bb-050cc5f1d83b",
   "metadata": {},
   "source": [
    "# 4. Selenium 패키지"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0e41275-c8e8-4ae0-abc1-61ed572b079d",
   "metadata": {},
   "source": [
    "## 4.1 find_element() 함수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b49e312a-5feb-4892-93f0-7db20faf8323",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'selenium.webdriver.remote.webelement.WebElement'>\n",
      "카페\n"
     ]
    }
   ],
   "source": [
    "from selenium.webdriver import Chrome, ChromeOptions\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.common.by import By\n",
    "\n",
    "#웹 드라이버를 동적으로 다운로드해서 실행abs\n",
    "driver = Chrome(service=Service(ChromeDriverManager().install()), options=ChromeOptions())\n",
    "#[참고] 로컬 컴퓨터에 설치되어 있는 웹 드라이버 실행 방식\n",
    "#s = Service('d:\\DEV\\chromedriver\\chromedriver.exe') #경로지정 예시\n",
    "#driver = Chrome(service=s)\n",
    "\n",
    "driver.get('https://www.daum.net')\n",
    "ele = driver.find_element(by=By.LINK_TEXT,value='카페')\n",
    "print(type(ele))\n",
    "print(ele.text)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8d2ba01-3dba-4b95-94f5-e199539e37d9",
   "metadata": {},
   "source": [
    "## 4.2 이벤트 제어하기"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9984a17a-bac4-42b8-aa71-6cf6485e92a0",
   "metadata": {},
   "source": [
    "### 4.2.1 click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d6f80001-3d2b-4e45-8c2b-ba2779ede2ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium.webdriver import Chrome, ChromeOptions\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.common.by import By\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "\n",
    "driver = Chrome(service=Service(ChromeDriverManager().install()),options=ChromeOptions())\n",
    "\n",
    "driver.get('https://www.naver.com')\n",
    "ele = driver.find_element(by=By.CSS_SELECTOR, value='#shortcutArea > ul > li:nth-child(5) > a')\n",
    "ele.click()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c6045bf-119d-49bc-8f61-e5ce071fbabe",
   "metadata": {},
   "source": [
    "### 4.2.2 send_keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fa6b681e-0007-419b-aa01-6f0285ec1ef4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium.webdriver import Chrome, ChromeOptions\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.common.by import By\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "from selenium.webdriver.common.keys import Keys #특수키 사용을 위한 클래스\n",
    "\n",
    "driver = Chrome(service=Service(ChromeDriverManager().install()),options=ChromeOptions())\n",
    "\n",
    "driver.get('https://www.naver.com')\n",
    "ele = driver.find_element(by=By.ID, value='query')\n",
    "ele.send_keys('python')\n",
    "ele.send_keys(Keys.ENTER)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cdf34b1-84bb-479b-b59f-23cdd0bc5e95",
   "metadata": {},
   "source": [
    "[실습] 네이버 로그인 하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "22230753-7f23-45f5-a280-267d965fd7fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium.webdriver import Chrome, ChromeOptions\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.common.by import By\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "\n",
    "driver = Chrome(service=Service(ChromeDriverManager().install()),options=ChromeOptions())\n",
    "\n",
    "driver.get('https://www.naver.com')\n",
    "ele = driver.find_element(by=By.CLASS_NAME, value='MyView-module__link_login___HpHMW')\n",
    "ele.click()\n",
    "\n",
    "my_id = 'dnrkdus1'\n",
    "my_pw = 'Wyeon3936'\n",
    "\n",
    "#로봇에 의해 클릭되지 못하도록 막았기 때문에 스크립트로 처리해야함abs\n",
    "#ele = driver.find_element(by=By.ID, value='id')\n",
    "#ele.send_keys(my_id)\n",
    "\n",
    "#ele = driver.find_element(by=By.ID, value='pw')\n",
    "#ele.send_keys(my_pw)\n",
    "\n",
    "driver.execute_script(f\"document.getElementById('id').value = '{my_id}'\")\n",
    "driver.execute_script(f\"document.getElementById('pw').value = '{my_pw}'\")\n",
    "\n",
    "ele = driver.find_element(by=By.CLASS_NAME, value ='btn_login')\n",
    "ele.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "52f865b1-c709-4e95-a957-d91bf05b13b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#로그인 상태 유지하기\n",
    "\n",
    "from selenium.webdriver import Chrome, ChromeOptions\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.common.by import By\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "\n",
    "driver = Chrome(service=Service(ChromeDriverManager().install()),options=ChromeOptions())\n",
    "\n",
    "driver.get('https://www.naver.com')\n",
    "ele = driver.find_element(by=By.CLASS_NAME, value='MyView-module__link_login___HpHMW')\n",
    "ele.click()\n",
    "\n",
    "my_id = 'dnrkdus1'\n",
    "my_pw = 'Wyeon3936'\n",
    "\n",
    "#로봇에 의해 클릭되지 못하도록 막았기 때문에 스크립트로 처리해야함abs\n",
    "#ele = driver.find_element(by=By.ID, value='id')\n",
    "#ele.send_keys(my_id)\n",
    "\n",
    "#ele = driver.find_element(by=By.ID, value='pw')\n",
    "#ele.send_keys(my_pw)\n",
    "\n",
    "driver.execute_script(f\"document.getElementById('id').value = '{my_id}'\")\n",
    "driver.execute_script(f\"document.getElementById('pw').value = '{my_pw}'\")\n",
    "\n",
    "#로그인 상태 유지 체크박스 클릭\n",
    "driver.execute_script(f'document.getElementById(\"keep\").value = \"on\"')\n",
    "\n",
    "ele = driver.find_element(by=By.CLASS_NAME, value ='btn_login')\n",
    "ele.click()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff57b548-4532-4775-b996-bdc365df1f0c",
   "metadata": {},
   "source": [
    "## 4.4 웹브라우저 자동 스크롤"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05f8f25a-4830-4ae2-9f9b-20ea190ff8c6",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### 4.4.1 구글에서 이미지 검색 후 검색결과 6번 스크롤 하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "98d0897f-d734-41a6-8ba6-7d8f685c03c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "last height: None\n",
      "new height: 13935\n",
      "------------------------------\n",
      "new height: 20631\n",
      "------------------------------\n",
      "new height: 27079\n",
      "------------------------------\n",
      "new height: 27079\n",
      "------------------------------\n",
      "new height: 27079\n",
      "------------------------------\n",
      "new height: 27079\n",
      "------------------------------\n"
     ]
    }
   ],
   "source": [
    "from selenium.webdriver import Chrome, ChromeOptions\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "import time\n",
    "\n",
    "#페이지가 로드될때까지 기다리는 시간\n",
    "SCROLL_PAUSE_TIME = 2\n",
    "\n",
    "driver = Chrome(service=Service(ChromeDriverManager().install()),options=ChromeOptions())\n",
    "driver.get('https://www.google.com')\n",
    "ele = driver.find_element(by=By.CLASS_NAME, value='gLFyf')\n",
    "ele.send_keys('python')\n",
    "ele.submit()\n",
    "\n",
    "driver.find_element(By.LINK_TEXT, '이미지').click()\n",
    "\n",
    "#페이지가 로드될때까지 기다림\n",
    "time.sleep(SCROLL_PAUSE_TIME)\n",
    "#최초 스크롤바의 높이값 읽기\n",
    "last_height = driver.execute_script('return document.body.scrollHight')\n",
    "print('last height:', last_height)\n",
    "for i in range(6):\n",
    "    driver.execute_script('window.scrollTo(0, document.body.scrollHeight)')\n",
    "    #(0. document.body.scrollHeight) 현재 윈도우의 스크롤 바를 0에부터 가장 밑(scrollHeight)까지 이동시켜라\n",
    "    time.sleep(SCROLL_PAUSE_TIME)\n",
    "    #로딩 된 후에는 새로운 높이값을 갖게 된다\n",
    "    #스크롤 바 이동으로 새로운 검색 결과가 로딩 후 변경된 새로운 스크롤 바의 높이 값 읽기\n",
    "    new_height = driver.execute_script('return document.body.scrollHeight')\n",
    "    print('new height:', new_height)\n",
    "    print('-'*30)\n",
    "\n",
    "#더이상 스크롤 될 페이지가 없을 경우 scrollHeight 값의 변화가 없다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54022ab5-9a25-4e95-8d59-afbe01babea5",
   "metadata": {},
   "source": [
    "### 4.4.2 구글에서 이미지 검색 후 검색 결과 무한 스크롤하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "eb697a06-0b79-40e0-91c7-c9d1192aa130",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "last height: None\n",
      "last height:None, new height:13915, scroll count: 1\n",
      "------------------------------\n",
      "last height:13915, new height:20611, scroll count: 2\n",
      "------------------------------\n",
      "last height:20611, new height:27059, scroll count: 3\n",
      "------------------------------\n",
      "last height:27059, new height:29905, scroll count: 4\n",
      "------------------------------\n",
      "last height:29905, new height:29905, scroll count: 5\n",
      "------------------------------\n"
     ]
    }
   ],
   "source": [
    "from selenium.webdriver import Chrome, ChromeOptions\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "import time\n",
    "\n",
    "#페이지가 로드될때까지 기다리는 시간\n",
    "SCROLL_PAUSE_TIME = 2\n",
    "\n",
    "driver = Chrome(service=Service(ChromeDriverManager().install()),options=ChromeOptions())\n",
    "driver.get('https://www.google.com')\n",
    "ele = driver.find_element(by=By.CLASS_NAME, value='gLFyf')\n",
    "ele.send_keys('python')\n",
    "ele.submit()\n",
    "\n",
    "driver.find_element(By.LINK_TEXT, '이미지').click()\n",
    "\n",
    "#페이지가 로드될때까지 기다림\n",
    "time.sleep(SCROLL_PAUSE_TIME)\n",
    "#최초 스크롤바의 높이값 읽기\n",
    "last_height = driver.execute_script('return document.body.scrollHight')\n",
    "print('last height:', last_height)\n",
    "\n",
    "#스크롤 횟수\n",
    "scroll_cnt = 0\n",
    "\n",
    "\n",
    "while True:\n",
    "    driver.execute_script('window.scrollTo(0, document.body.scrollHeight)')\n",
    "    #(0. document.body.scrollHeight) 현재 윈도우의 스크롤 바를 0에부터 가장 밑(scrollHeight)까지 이동시켜라\n",
    "    scroll_cnt += 1\n",
    "    time.sleep(SCROLL_PAUSE_TIME)\n",
    "    #로딩 된 후에는 새로운 높이값을 갖게 된다\n",
    "    #스크롤 바 이동으로 새로운 검색 결과가 로딩 후 변경된 새로운 스크롤 바의 높이 값 읽기\n",
    "    new_height = driver.execute_script('return document.body.scrollHeight')\n",
    "    print(f'last height:{last_height}, new height:{new_height}, scroll count: {scroll_cnt}')\n",
    "    print('-'*30)\n",
    "    if last_height != new_height: # 계속해서 new_height 값이 변경되면\n",
    "        last_height = new_height\n",
    "    else: #더이상 nnew_height의 변경이 없으면\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a45a97e-90d3-4f63-8f26-89a434c07c1e",
   "metadata": {},
   "source": [
    "### 4.4.3 구글에서 이미지 검색 후 썸네일 이미지 클릭하고 원본 이미지 주소 수집하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f87f7c7d-8f40-4636-b61b-b9a4d04b57a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "last height: None\n",
      "last height:None, new height:7239, scroll count: 1\n",
      "------------------------------\n",
      "last height:7239, new height:7239, scroll count: 2\n",
      "------------------------------\n",
      "100\n",
      "[1]:https://upload.wikimedia.org/wikipedia/commons/thumb/c/c3/Python-logo-notext.svg/800px-Python-logo-notext.svg.png\n",
      "[2]:https://velog.velcdn.com/images/deep-of-machine/post/3f778fa2-2b43-42b3-9233-091424be7d73/image.png\n",
      "[3]:https://i.namu.wiki/i/mxMv5lNX8m8lUwu7yTjN6eNZh8JVuI6a_chEyMRc4V9oECkhVIl7OiPiGIOllv14uDVNuwRPVco8abCPe5xOiQ.svg\n",
      "[4]:https://images.velog.io/images/pm1100tm/post/30e9dc94-96d0-41b3-9f2f-d814e839a796/python.jpg\n",
      "[5]:https://upload.wikimedia.org/wikipedia/commons/thumb/0/0a/Python.svg/800px-Python.svg.png\n",
      "[6]:https://i.namu.wiki/i/pHxeJONxIv51qQsN2ac5nX3shPEmiSlKtGVATZXUE22NHGyw9v7_Aqto6aSoCU9ODz3RKtTKCEP0E0OI7TlxMQ.webp\n",
      "[7]:https://fineproxy.org/wp-content/uploads/2023/05/Python.jpg\n",
      "[8]:https://www.askedtech.com/api/kords/admin/product/image.jpg?type=org&id=20688\n",
      "[9]:https://store-images.s-microsoft.com/image/apps.46763.13683872343053742.6c777826-d7ea-427a-942f-7dbfb474c121.7cd9c7f0-9cd8-4686-bd82-f7f4a18971ec?h=464\n",
      "[10]:https://mblogthumb-phinf.pstatic.net/MjAyMjAyMTJfNSAg/MDAxNjQ0NTkzNzE5MzQ1.q5g3zqnCq2Rt1xUmpSFx2xWRQTl4VmngS8FGT7eGD0Ig.UKr_wLSCCg8PD-v8TfDddCKFIWhKoeqh5lZM09FVrsYg.PNG.sw4r/image.png?type=w800&jopt=2\n",
      "[11]:https://www.unite.ai/wp-content/uploads/2022/04/AI-Python-Libraries.png\n",
      "[12]:https://i.natgeofe.com/k/3373927f-fa15-4c55-bf49-73f44073b768/burmese-python-tree_2x3.jpg\n",
      "[13]:https://www.snugarchive.com/static/06cc3be354c9abae90b6ebc9469d7ff1/84d4b/featured-image-python-logo.png\n",
      "[14]:https://images.velog.io/images/taeil77/post/0860d033-75cf-4101-b236-1a261c8c2c8a/python.png\n",
      "[15]:https://projects-static.raspberrypi.org/collections/assets/python_placeholder.png\n",
      "[16]:https://www.udacity.com/blog/wp-content/uploads/2020/12/Python-Tutorial_Blog-scaled.jpeg\n",
      "[17]:https://img1.daumcdn.net/thumb/R800x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2Fylgth%2FbtrJD4skdzV%2FBpPtZfi7QnkHzZaAr43LNk%2Fimg.png\n",
      "[18]:https://onlinedegrees.sandiego.edu/wp-content/uploads/2023/05/6-careers-you-can-get-with-python.jpg\n",
      "[19]:https://miro.medium.com/v2/resize:fit:638/1*Wa4aTPXFq5Zv5bAKRVt3AA.png\n",
      "[20]:https://upload.wikimedia.org/wikipedia/commons/1/10/Brooding_female_Python_molurus_bivittatus.jpg\n"
     ]
    }
   ],
   "source": [
    "from selenium.webdriver import Chrome, ChromeOptions\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "import time\n",
    "\n",
    "#페이지가 로드될때까지 기다리는 시간\n",
    "SCROLL_PAUSE_TIME = 2\n",
    "IMAGE_EXTRACT_NUM = 20 #이미지 추출 개수\n",
    "SEARCH_KEYWORD = 'python'\n",
    "\n",
    "##### 웹 드라이버 실행 및 구글 접속 #####\n",
    "driver = Chrome(service=Service(ChromeDriverManager().install()),options=ChromeOptions())\n",
    "driver.get('https://www.google.com')\n",
    "\n",
    "\n",
    "###### 검색 #######\n",
    "ele = driver.find_element(by=By.CLASS_NAME, value='gLFyf')\n",
    "ele.send_keys('python')\n",
    "ele.submit()\n",
    "\n",
    "###### 이미지 검색 결과 페이지 이동 ########\n",
    "driver.find_element(By.LINK_TEXT, '이미지').click()\n",
    "\n",
    "\n",
    "time.sleep(SCROLL_PAUSE_TIME) #페이지가 로드될때까지 기다림\n",
    "\n",
    "\n",
    "######### 이미지 검색결과 페이지 스크롤 #########\n",
    "#최초 스크롤바의 높이값 읽기\n",
    "last_height = driver.execute_script('return document.body.scrollHight')\n",
    "print('last height:', last_height)\n",
    "\n",
    "#스크롤 횟수\n",
    "scroll_cnt = 0\n",
    "\n",
    "\n",
    "while True:\n",
    "    driver.execute_script('window.scrollTo(0, document.body.scrollHeight)')\n",
    "    #(0. document.body.scrollHeight) 현재 윈도우의 스크롤 바를 0에부터 가장 밑(scrollHeight)까지 이동시켜라\n",
    "    scroll_cnt += 1\n",
    "    time.sleep(SCROLL_PAUSE_TIME)\n",
    "    #로딩 된 후에는 새로운 높이값을 갖게 된다\n",
    "    #스크롤 바 이동으로 새로운 검색 결과가 로딩 후 변경된 새로운 스크롤 바의 높이 값 읽기\n",
    "    new_height = driver.execute_script('return document.body.scrollHeight')\n",
    "    print(f'last height:{last_height}, new height:{new_height}, scroll count: {scroll_cnt}')\n",
    "    print('-'*30)\n",
    "    if last_height != new_height: # 계속해서 new_height 값이 변경되면\n",
    "        last_height = new_height\n",
    "    else: #더이상 nnew_height의 변경이 없으면\n",
    "        break\n",
    "\n",
    "\n",
    "\n",
    "####### 이미지 선택 및 해당 이미지 src 추출 #########\n",
    "imgs = driver.find_elements(By.CSS_SELECTOR, '#rso > div > div > div.wH6SXe.u32vCb > div > div > div > div.czzyk.XOEbc > h3 > a')\n",
    "print(len(imgs))\n",
    "img_src_list=[]\n",
    "img_cnt = 0\n",
    "for img in imgs:\n",
    "    try:\n",
    "        img.click()\n",
    "        time.sleep(1.5)\n",
    "        img_src = driver.find_element(By.CSS_SELECTOR, '#Sva75c > div.A8mJGd.NDuZHe.OGftbe-N7Eqid-H9tDt > div.LrPjRb > div.AQyBn > div.tvh9oe.BIB1wf > c-wiz > div > div > div > div > div.v6bUne > div.p7sI2.PUxBg > a > img.sFlh5c.pT0Scc.iPVvYb').get_attribute('src')\n",
    "        img_cnt += 1\n",
    "        print(f'[{img_cnt}]:{img_src}')\n",
    "        img_src_list.append(img_src)\n",
    "        if img_cnt == IMAGE_EXTRACT_NUM: break\n",
    "    except:\n",
    "        img_cnt -= 1 #에러가 발생했을 시 지속되도록\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf34e2ad-9b3b-49b2-bee2-046a7a5ba870",
   "metadata": {},
   "source": [
    "### 4.4.4 구글에서 이미지 검색 후 파일로 저장하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "a2b66ea1-a3cc-407e-815b-90328509dcec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "last height: None\n",
      "last height:None, new height:13935, scroll count: 1\n",
      "------------------------------\n",
      "last height:13935, new height:20631, scroll count: 2\n",
      "------------------------------\n",
      "last height:20631, new height:27214, scroll count: 3\n",
      "------------------------------\n",
      "last height:27214, new height:30193, scroll count: 4\n",
      "------------------------------\n",
      "last height:30193, new height:30193, scroll count: 5\n",
      "------------------------------\n",
      "440\n",
      "[1]:https://upload.wikimedia.org/wikipedia/commons/thumb/c/c3/Python-logo-notext.svg/800px-Python-logo-notext.svg.png\n",
      "[2]:https://velog.velcdn.com/images/deep-of-machine/post/3f778fa2-2b43-42b3-9233-091424be7d73/image.png\n",
      "[3]:https://i.namu.wiki/i/mxMv5lNX8m8lUwu7yTjN6eNZh8JVuI6a_chEyMRc4V9oECkhVIl7OiPiGIOllv14uDVNuwRPVco8abCPe5xOiQ.svg\n",
      "[4]:https://images.velog.io/images/pm1100tm/post/30e9dc94-96d0-41b3-9f2f-d814e839a796/python.jpg\n",
      "[5]:https://i.namu.wiki/i/pHxeJONxIv51qQsN2ac5nX3shPEmiSlKtGVATZXUE22NHGyw9v7_Aqto6aSoCU9ODz3RKtTKCEP0E0OI7TlxMQ.webp\n",
      "[6]:https://upload.wikimedia.org/wikipedia/commons/thumb/0/0a/Python.svg/800px-Python.svg.png\n",
      "[7]:https://fineproxy.org/wp-content/uploads/2023/05/Python.jpg\n",
      "[8]:https://www.askedtech.com/api/kords/admin/product/image.jpg?type=org&id=20688\n",
      "[9]:https://store-images.s-microsoft.com/image/apps.46763.13683872343053742.6c777826-d7ea-427a-942f-7dbfb474c121.7cd9c7f0-9cd8-4686-bd82-f7f4a18971ec?h=464\n",
      "[10]:https://mblogthumb-phinf.pstatic.net/MjAyMjAyMTJfNSAg/MDAxNjQ0NTkzNzE5MzQ1.q5g3zqnCq2Rt1xUmpSFx2xWRQTl4VmngS8FGT7eGD0Ig.UKr_wLSCCg8PD-v8TfDddCKFIWhKoeqh5lZM09FVrsYg.PNG.sw4r/image.png?type=w800&jopt=2\n",
      "[11]:https://www.unite.ai/wp-content/uploads/2022/04/AI-Python-Libraries.png\n",
      "[12]:https://www.snugarchive.com/static/06cc3be354c9abae90b6ebc9469d7ff1/84d4b/featured-image-python-logo.png\n",
      "[13]:https://images.velog.io/images/taeil77/post/0860d033-75cf-4101-b236-1a261c8c2c8a/python.png\n",
      "[14]:https://projects-static.raspberrypi.org/collections/assets/python_placeholder.png\n",
      "[15]:https://www.udacity.com/blog/wp-content/uploads/2020/12/Python-Tutorial_Blog-scaled.jpeg\n",
      "[16]:https://img1.daumcdn.net/thumb/R800x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2Fylgth%2FbtrJD4skdzV%2FBpPtZfi7QnkHzZaAr43LNk%2Fimg.png\n",
      "[17]:https://onlinedegrees.sandiego.edu/wp-content/uploads/2023/05/6-careers-you-can-get-with-python.jpg\n",
      "[18]:https://miro.medium.com/v2/resize:fit:638/1*Wa4aTPXFq5Zv5bAKRVt3AA.png\n",
      "[19]:https://upload.wikimedia.org/wikipedia/commons/1/10/Brooding_female_Python_molurus_bivittatus.jpg\n",
      "[20]:https://prepinstadotcom.s3.ap-south-1.amazonaws.com/wp-content/uploads/2020/07/python-removebg-preview.webp\n"
     ]
    }
   ],
   "source": [
    "from selenium.webdriver import Chrome, ChromeOptions\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "import time\n",
    "\n",
    "#페이지가 로드될때까지 기다리는 시간\n",
    "SCROLL_PAUSE_TIME = 2\n",
    "IMAGE_EXTRACT_NUM = 20 #이미지 추출 개수\n",
    "SEARCH_KEYWORD = 'python'\n",
    "\n",
    "##### 웹 드라이버 실행 및 구글 접속 #####\n",
    "driver = Chrome(service=Service(ChromeDriverManager().install()),options=ChromeOptions())\n",
    "driver.get('https://www.google.com')\n",
    "\n",
    "\n",
    "###### 검색 #######\n",
    "ele = driver.find_element(by=By.CLASS_NAME, value='gLFyf')\n",
    "ele.send_keys('python')\n",
    "ele.submit()\n",
    "\n",
    "###### 이미지 검색 결과 페이지 이동 ########\n",
    "driver.find_element(By.LINK_TEXT, '이미지').click()\n",
    "\n",
    "\n",
    "time.sleep(SCROLL_PAUSE_TIME) #페이지가 로드될때까지 기다림\n",
    "\n",
    "\n",
    "######### 이미지 검색결과 페이지 스크롤 #########\n",
    "#최초 스크롤바의 높이값 읽기\n",
    "last_height = driver.execute_script('return document.body.scrollHight')\n",
    "print('last height:', last_height)\n",
    "\n",
    "#스크롤 횟수\n",
    "scroll_cnt = 0\n",
    "\n",
    "\n",
    "while True:\n",
    "    driver.execute_script('window.scrollTo(0, document.body.scrollHeight)')\n",
    "    #(0. document.body.scrollHeight) 현재 윈도우의 스크롤 바를 0에부터 가장 밑(scrollHeight)까지 이동시켜라\n",
    "    scroll_cnt += 1\n",
    "    time.sleep(SCROLL_PAUSE_TIME)\n",
    "    #로딩 된 후에는 새로운 높이값을 갖게 된다\n",
    "    #스크롤 바 이동으로 새로운 검색 결과가 로딩 후 변경된 새로운 스크롤 바의 높이 값 읽기\n",
    "    new_height = driver.execute_script('return document.body.scrollHeight')\n",
    "    print(f'last height:{last_height}, new height:{new_height}, scroll count: {scroll_cnt}')\n",
    "    print('-'*30)\n",
    "    if last_height != new_height: # 계속해서 new_height 값이 변경되면\n",
    "        last_height = new_height\n",
    "    else: #더이상 nnew_height의 변경이 없으면\n",
    "        break\n",
    "\n",
    "\n",
    "\n",
    "####### 이미지 선택 및 해당 이미지 src 추출 #########\n",
    "imgs = driver.find_elements(By.CSS_SELECTOR, '#rso > div > div > div.wH6SXe.u32vCb > div > div > div > div.czzyk.XOEbc > h3 > a')\n",
    "print(len(imgs))\n",
    "img_src_list=[]\n",
    "img_cnt = 0\n",
    "for img in imgs:\n",
    "    try:\n",
    "        img.click()\n",
    "        time.sleep(1.5)\n",
    "        img_src = driver.find_element(By.CSS_SELECTOR, '#Sva75c > div.A8mJGd.NDuZHe.OGftbe-N7Eqid-H9tDt > div.LrPjRb > div.AQyBn > div.tvh9oe.BIB1wf > c-wiz > div > div > div > div > div.v6bUne > div.p7sI2.PUxBg > a > img.sFlh5c.pT0Scc.iPVvYb').get_attribute('src')\n",
    "        img_cnt += 1\n",
    "        print(f'[{img_cnt}]:{img_src}')\n",
    "        img_src_list.append(img_src)\n",
    "        if img_cnt == IMAGE_EXTRACT_NUM: break\n",
    "    except:\n",
    "        img_cnt -= 1 #에러가 발생했을 시 지속되도록\n",
    "\n",
    "###### 검색 이미지 파일로 저장 ########\n",
    "import os\n",
    "import requests\n",
    "\n",
    "ts = time.localtime()\n",
    "path = 'c:/Temp/'\n",
    "now = '{}.{}.{}.{}.{}.{}'.format(ts.tm_year, ts.tm_mon, ts.tm_mday, ts.tm_hour, ts.tm_min, ts.tm_sec)\n",
    "dir = SEARCH_KEYWORD+'/'+now+'/'\n",
    "os.chdir(path)\n",
    "if not os.path.exists(dir):\n",
    "    os.makedirs(dir)\n",
    "\n",
    "file_no = 1\n",
    "os.chdir(path+dir)\n",
    "for url in img_src_list:\n",
    "    extension = url.split('.')[-1] #원본 이미지에서 가져온 확장자\n",
    "    ext = ''\n",
    "    if extension in ['jpg','JPG','jpeg','JPEG','png','PNG','gif','GIF']:\n",
    "        ext = '.'+extension\n",
    "    else:\n",
    "        ext = '.jpg'\n",
    "\n",
    "    file_name = str(file_no)+'-'+SEARCH_KEYWORD+ext\n",
    "    file_no += 1\n",
    "    res = requests.get(url)\n",
    "    with open(file_name, 'wb') as f:\n",
    "        f.write(res.content)\n",
    "driver.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "663465a5-3f04-4291-9970-490e215e549f",
   "metadata": {},
   "outputs": [],
   "source": [
    "URL = 'https://www.selenium.dev/selenium/web/formPage.html'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9cdfc314-6612-4a9d-9174-4b04806adf12",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from selenium.webdriver import Chrome, ChromeOptions\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "from selenium.webdriver.support.ui import Select # select form 제어 클래스 import함.`\n",
    "\n",
    "URL = 'https://www.selenium.dev/selenium/web/formPage.html'\n",
    "\n",
    "driver = Chrome(service=Service(ChromeDriverManager().install()), options=ChromeOptions())\n",
    "driver.get(URL)\n",
    "\n",
    "ele = driver.find_element(By.NAME, 'selectomatic')\n",
    "select = Select(ele)\n",
    "\n",
    "#인덱스 기준으로 선택하기\n",
    "#select.select_by_index(2)\n",
    "\n",
    "#보여지는 선택값 텍스트로 선택하기\n",
    "#select.select_by_visible_text('Four')\n",
    "\n",
    "#option 요소의 값으로 선택하기\n",
    "#select.select_by_value('four')\n",
    "\n",
    "#select 태그에 onchange 속성이 있어서 select 클래스를 사용할 수 없을 때\n",
    "driver.find_element(By.CSS_SELECTOR,'option[value=\"four\"]').click()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3583f7b-179b-437f-9ffe-ce90e1296b1f",
   "metadata": {},
   "source": [
    "[실습] yes24에서 파이썬 도서 검색하기\n",
    "- yes24 사이트에서 파이썬 도서 검색 -> 검색 결과를 120개 선택\n",
    "- 검색 결과에서 도서 평점이 9.6 이상인 도서 제목과 가격, 평점 출력한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0ba3b80b-7e51-43a9-85af-09ff9b1fe5f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from selenium.webdriver import Chrome, ChromeOptions\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "from selenium.webdriver.support.ui import Select # select form 제어 클래스 import함.`\n",
    "\n",
    "URL = 'https://www.yes24.com'\n",
    "\n",
    "driver = Chrome(service=Service(ChromeDriverManager().install()), options=ChromeOptions())\n",
    "driver.get(URL)\n",
    "\n",
    "ele=driver.find_element(By.ID, 'query')\n",
    "ele.send_keys('파이썬')\n",
    "ele.send_keys(Keys.ENTER)\n",
    "\n",
    "driver.find_element(By.CSS_SELECTOR, '#stat_gb > option[value=\"120\"]').click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "4721bc97-3daa-4db4-a22d-381be05b83ce",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NoSuchWindowException",
     "evalue": "Message: no such window: target window already closed\nfrom unknown error: web view not found\n  (Session info: chrome=123.0.6312.106)\nStacktrace:\n\tGetHandleVerifier [0x00BB4CE3+225091]\n\t(No symbol) [0x00AE4E31]\n\t(No symbol) [0x00989A7A]\n\t(No symbol) [0x0096E312]\n\t(No symbol) [0x009E517B]\n\t(No symbol) [0x009F55A6]\n\t(No symbol) [0x009DF2F6]\n\t(No symbol) [0x009B79B9]\n\t(No symbol) [0x009B879D]\n\tsqlite3_dbdata_init [0x01029A83+4064547]\n\tsqlite3_dbdata_init [0x0103108A+4094762]\n\tsqlite3_dbdata_init [0x0102B988+4072488]\n\tsqlite3_dbdata_init [0x00D2C9E9+930953]\n\t(No symbol) [0x00AF0804]\n\t(No symbol) [0x00AEAD28]\n\t(No symbol) [0x00AEAE51]\n\t(No symbol) [0x00ADCAC0]\n\tBaseThreadInitThunk [0x75497BA9+25]\n\tRtlInitializeExceptionChain [0x7787BDAB+107]\n\tRtlClearBits [0x7787BD2F+191]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNoSuchWindowException\u001b[0m                     Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[32], line 5\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mrequests\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mbs4\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m BeautifulSoup\n\u001b[1;32m----> 5\u001b[0m soup \u001b[38;5;241m=\u001b[39m BeautifulSoup(driver\u001b[38;5;241m.\u001b[39mpage_source, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlxml\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      6\u001b[0m book_list \u001b[38;5;241m=\u001b[39m soup\u001b[38;5;241m.\u001b[39mfind(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mul\u001b[39m\u001b[38;5;124m'\u001b[39m, attrs\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mid\u001b[39m\u001b[38;5;124m'\u001b[39m:\u001b[38;5;124m'\u001b[39m\u001b[38;5;124myesSchList\u001b[39m\u001b[38;5;124m'\u001b[39m})\n\u001b[0;32m      7\u001b[0m books \u001b[38;5;241m=\u001b[39m book_list\u001b[38;5;241m.\u001b[39mfind_all(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mli\u001b[39m\u001b[38;5;124m'\u001b[39m, attrs\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m:\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m})\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\selenium\\webdriver\\remote\\webdriver.py:448\u001b[0m, in \u001b[0;36mWebDriver.page_source\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    439\u001b[0m \u001b[38;5;129m@property\u001b[39m\n\u001b[0;32m    440\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpage_source\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mstr\u001b[39m:\n\u001b[0;32m    441\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Gets the source of the current page.\u001b[39;00m\n\u001b[0;32m    442\u001b[0m \n\u001b[0;32m    443\u001b[0m \u001b[38;5;124;03m    :Usage:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    446\u001b[0m \u001b[38;5;124;03m            driver.page_source\u001b[39;00m\n\u001b[0;32m    447\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 448\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexecute(Command\u001b[38;5;241m.\u001b[39mGET_PAGE_SOURCE)[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalue\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\selenium\\webdriver\\remote\\webdriver.py:347\u001b[0m, in \u001b[0;36mWebDriver.execute\u001b[1;34m(self, driver_command, params)\u001b[0m\n\u001b[0;32m    345\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcommand_executor\u001b[38;5;241m.\u001b[39mexecute(driver_command, params)\n\u001b[0;32m    346\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m response:\n\u001b[1;32m--> 347\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39merror_handler\u001b[38;5;241m.\u001b[39mcheck_response(response)\n\u001b[0;32m    348\u001b[0m     response[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalue\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_unwrap_value(response\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalue\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[0;32m    349\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\selenium\\webdriver\\remote\\errorhandler.py:229\u001b[0m, in \u001b[0;36mErrorHandler.check_response\u001b[1;34m(self, response)\u001b[0m\n\u001b[0;32m    227\u001b[0m         alert_text \u001b[38;5;241m=\u001b[39m value[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124malert\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    228\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exception_class(message, screen, stacktrace, alert_text)  \u001b[38;5;66;03m# type: ignore[call-arg]  # mypy is not smart enough here\u001b[39;00m\n\u001b[1;32m--> 229\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m exception_class(message, screen, stacktrace)\n",
      "\u001b[1;31mNoSuchWindowException\u001b[0m: Message: no such window: target window already closed\nfrom unknown error: web view not found\n  (Session info: chrome=123.0.6312.106)\nStacktrace:\n\tGetHandleVerifier [0x00BB4CE3+225091]\n\t(No symbol) [0x00AE4E31]\n\t(No symbol) [0x00989A7A]\n\t(No symbol) [0x0096E312]\n\t(No symbol) [0x009E517B]\n\t(No symbol) [0x009F55A6]\n\t(No symbol) [0x009DF2F6]\n\t(No symbol) [0x009B79B9]\n\t(No symbol) [0x009B879D]\n\tsqlite3_dbdata_init [0x01029A83+4064547]\n\tsqlite3_dbdata_init [0x0103108A+4094762]\n\tsqlite3_dbdata_init [0x0102B988+4072488]\n\tsqlite3_dbdata_init [0x00D2C9E9+930953]\n\t(No symbol) [0x00AF0804]\n\t(No symbol) [0x00AEAD28]\n\t(No symbol) [0x00AEAE51]\n\t(No symbol) [0x00ADCAC0]\n\tBaseThreadInitThunk [0x75497BA9+25]\n\tRtlInitializeExceptionChain [0x7787BDAB+107]\n\tRtlClearBits [0x7787BD2F+191]\n"
     ]
    }
   ],
   "source": [
    "# 데이터 가져오기\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "soup = BeautifulSoup(driver.page_source, 'lxml')\n",
    "book_list = soup.find('ul', attrs={'id':'yesSchList'})\n",
    "books = book_list.find_all('li', attrs={'':''})\n",
    "print('검색 도서 권수:', len(books))\n",
    "\n",
    "count=0\n",
    "for i, book in enumerate(books, 1): # index(i) 시작값 1로 설정. 'li'에 다른 정보 태그들이 있으므로 index가 무의미해짐. 따라서 enumerate 사용 안 해도 무방. 예컨대 book in books도 가능\n",
    "    rating = book.find('span', attrs={'class':'rating_grade'})\n",
    "    if not rating: continue # 평점이 없는 책은 None -> False 리턴. 이 경우 이하 내용 실행을 skip함. 다시 윗줄로.\n",
    "    rating = float(rating.find('em').get_text()) # soup find 함수 -> string값 리턴\n",
    "    if rating > 9.6:\n",
    "        count+=1\n",
    "        title = book.find('a', attrs={'class':'gd_name'}).get_text()\n",
    "        price = book.find('strong', attrs={'class':'txt_num'}).get_text()\n",
    "        print(f'{count:03d} | {title} | {price} | 평점: {rating}')\n",
    "driver.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb30dfa2-66dc-42e0-9897-205f7fa127ba",
   "metadata": {},
   "source": [
    "[실습] 메가박스 영화 감상평"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "d71e06e3-c01e-4e56-8417-5a21e589d737",
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium.webdriver import Chrome, ChromeOptions\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "from bs4 import BeautifulSoup\n",
    "import time\n",
    "\n",
    "PAUSE_TIME = 2.5\n",
    "\n",
    "URL = 'https://www.megabox.co.kr/movie'\n",
    "driver = Chrome(service=Service(ChromeDriverManager().install()), options=ChromeOptions())\n",
    "driver.get(URL)\n",
    "movie = driver.find_element(By.CSS_SELECTOR, '#movieList > li:nth-child(4) > div.movie-list-info > div.movie-score > a').send_keys(Keys.ENTER) # 파묘 클릭. click()함수 에러 발생 시 ENTER로 대체 가능.\n",
    "time.sleep(PAUSE_TIME)\n",
    "driver.find_element(By.LINK_TEXT, '실관람평').click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "7e53643b-6e33-415c-ba29-9e0b72783bbd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NoSuchWindowException",
     "evalue": "Message: no such window: target window already closed\nfrom unknown error: web view not found\n  (Session info: chrome=123.0.6312.106)\nStacktrace:\n\tGetHandleVerifier [0x00BB4CE3+225091]\n\t(No symbol) [0x00AE4E31]\n\t(No symbol) [0x00989A7A]\n\t(No symbol) [0x0096E312]\n\t(No symbol) [0x009E517B]\n\t(No symbol) [0x009F55A6]\n\t(No symbol) [0x009DF2F6]\n\t(No symbol) [0x009B79B9]\n\t(No symbol) [0x009B879D]\n\tsqlite3_dbdata_init [0x01029A83+4064547]\n\tsqlite3_dbdata_init [0x0103108A+4094762]\n\tsqlite3_dbdata_init [0x0102B988+4072488]\n\tsqlite3_dbdata_init [0x00D2C9E9+930953]\n\t(No symbol) [0x00AF0804]\n\t(No symbol) [0x00AEAD28]\n\t(No symbol) [0x00AEAE51]\n\t(No symbol) [0x00ADCAC0]\n\tBaseThreadInitThunk [0x75497BA9+25]\n\tRtlInitializeExceptionChain [0x7787BDAB+107]\n\tRtlClearBits [0x7787BD2F+191]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNoSuchWindowException\u001b[0m                     Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[40], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m ratings \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m      2\u001b[0m comments \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m----> 4\u001b[0m bs \u001b[38;5;241m=\u001b[39m BeautifulSoup(driver\u001b[38;5;241m.\u001b[39mpage_source, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlxml\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      5\u001b[0m result \u001b[38;5;241m=\u001b[39m bs\u001b[38;5;241m.\u001b[39mfind_all(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mli\u001b[39m\u001b[38;5;124m'\u001b[39m, attrs \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mclass\u001b[39m\u001b[38;5;124m'\u001b[39m:\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtype01 oneContentTag\u001b[39m\u001b[38;5;124m'\u001b[39m})\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m c \u001b[38;5;129;01min\u001b[39;00m result:\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\selenium\\webdriver\\remote\\webdriver.py:448\u001b[0m, in \u001b[0;36mWebDriver.page_source\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    439\u001b[0m \u001b[38;5;129m@property\u001b[39m\n\u001b[0;32m    440\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpage_source\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mstr\u001b[39m:\n\u001b[0;32m    441\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Gets the source of the current page.\u001b[39;00m\n\u001b[0;32m    442\u001b[0m \n\u001b[0;32m    443\u001b[0m \u001b[38;5;124;03m    :Usage:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    446\u001b[0m \u001b[38;5;124;03m            driver.page_source\u001b[39;00m\n\u001b[0;32m    447\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 448\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexecute(Command\u001b[38;5;241m.\u001b[39mGET_PAGE_SOURCE)[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalue\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\selenium\\webdriver\\remote\\webdriver.py:347\u001b[0m, in \u001b[0;36mWebDriver.execute\u001b[1;34m(self, driver_command, params)\u001b[0m\n\u001b[0;32m    345\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcommand_executor\u001b[38;5;241m.\u001b[39mexecute(driver_command, params)\n\u001b[0;32m    346\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m response:\n\u001b[1;32m--> 347\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39merror_handler\u001b[38;5;241m.\u001b[39mcheck_response(response)\n\u001b[0;32m    348\u001b[0m     response[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalue\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_unwrap_value(response\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalue\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[0;32m    349\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\selenium\\webdriver\\remote\\errorhandler.py:229\u001b[0m, in \u001b[0;36mErrorHandler.check_response\u001b[1;34m(self, response)\u001b[0m\n\u001b[0;32m    227\u001b[0m         alert_text \u001b[38;5;241m=\u001b[39m value[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124malert\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    228\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exception_class(message, screen, stacktrace, alert_text)  \u001b[38;5;66;03m# type: ignore[call-arg]  # mypy is not smart enough here\u001b[39;00m\n\u001b[1;32m--> 229\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m exception_class(message, screen, stacktrace)\n",
      "\u001b[1;31mNoSuchWindowException\u001b[0m: Message: no such window: target window already closed\nfrom unknown error: web view not found\n  (Session info: chrome=123.0.6312.106)\nStacktrace:\n\tGetHandleVerifier [0x00BB4CE3+225091]\n\t(No symbol) [0x00AE4E31]\n\t(No symbol) [0x00989A7A]\n\t(No symbol) [0x0096E312]\n\t(No symbol) [0x009E517B]\n\t(No symbol) [0x009F55A6]\n\t(No symbol) [0x009DF2F6]\n\t(No symbol) [0x009B79B9]\n\t(No symbol) [0x009B879D]\n\tsqlite3_dbdata_init [0x01029A83+4064547]\n\tsqlite3_dbdata_init [0x0103108A+4094762]\n\tsqlite3_dbdata_init [0x0102B988+4072488]\n\tsqlite3_dbdata_init [0x00D2C9E9+930953]\n\t(No symbol) [0x00AF0804]\n\t(No symbol) [0x00AEAD28]\n\t(No symbol) [0x00AEAE51]\n\t(No symbol) [0x00ADCAC0]\n\tBaseThreadInitThunk [0x75497BA9+25]\n\tRtlInitializeExceptionChain [0x7787BDAB+107]\n\tRtlClearBits [0x7787BD2F+191]\n"
     ]
    }
   ],
   "source": [
    "ratings = []\n",
    "comments = []\n",
    "\n",
    "bs = BeautifulSoup(driver.page_source, 'lxml')\n",
    "result = bs.find_all('li', attrs = {'class':'type01 oneContentTag'})\n",
    "for c in result:\n",
    "    rating = int(c.find('div', attrs = {'class':'story-point'}).text)\n",
    "    comment = c.find('div', attrs ={'class':'story-txt'}).text.strip()\n",
    "    print(rating, comment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "eaa01caa-2f60-477e-9526-66e2609294b9",
   "metadata": {},
   "outputs": [
    {
     "ename": "NoSuchWindowException",
     "evalue": "Message: no such window: target window already closed\nfrom unknown error: web view not found\n  (Session info: chrome=123.0.6312.106)\nStacktrace:\n\tGetHandleVerifier [0x00BB4CE3+225091]\n\t(No symbol) [0x00AE4E31]\n\t(No symbol) [0x00989A7A]\n\t(No symbol) [0x0096E312]\n\t(No symbol) [0x009E517B]\n\t(No symbol) [0x009F55A6]\n\t(No symbol) [0x009DF2F6]\n\t(No symbol) [0x009B79B9]\n\t(No symbol) [0x009B879D]\n\tsqlite3_dbdata_init [0x01029A83+4064547]\n\tsqlite3_dbdata_init [0x0103108A+4094762]\n\tsqlite3_dbdata_init [0x0102B988+4072488]\n\tsqlite3_dbdata_init [0x00D2C9E9+930953]\n\t(No symbol) [0x00AF0804]\n\t(No symbol) [0x00AEAD28]\n\t(No symbol) [0x00AEAE51]\n\t(No symbol) [0x00ADCAC0]\n\tBaseThreadInitThunk [0x75497BA9+25]\n\tRtlInitializeExceptionChain [0x7787BDAB+107]\n\tRtlClearBits [0x7787BD2F+191]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNoSuchWindowException\u001b[0m                     Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[41], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# 페이지 번호 클릭 테스트\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m driver\u001b[38;5;241m.\u001b[39mfind_element(By\u001b[38;5;241m.\u001b[39mCSS_SELECTOR, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m#contentData > div > div.movie-idv-story > nav > a.control.last\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;241m.\u001b[39mclick() \u001b[38;5;66;03m# 첫 페이지 CSS 선택자\u001b[39;00m\n\u001b[0;32m      3\u001b[0m time\u001b[38;5;241m.\u001b[39msleep(PAUSE_TIME)\n\u001b[0;32m      4\u001b[0m total_page_num \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m(driver\u001b[38;5;241m.\u001b[39mfind_element(By\u001b[38;5;241m.\u001b[39mCSS_SELECTOR, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m#contentData > div > div.movie-idv-story > nav > strong\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;241m.\u001b[39mtext) \u001b[38;5;66;03m# 마지막 페이지 CSS 선택자 -> for문 반복회수 확인\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\selenium\\webdriver\\remote\\webdriver.py:741\u001b[0m, in \u001b[0;36mWebDriver.find_element\u001b[1;34m(self, by, value)\u001b[0m\n\u001b[0;32m    738\u001b[0m     by \u001b[38;5;241m=\u001b[39m By\u001b[38;5;241m.\u001b[39mCSS_SELECTOR\n\u001b[0;32m    739\u001b[0m     value \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m[name=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mvalue\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m]\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m--> 741\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexecute(Command\u001b[38;5;241m.\u001b[39mFIND_ELEMENT, {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124musing\u001b[39m\u001b[38;5;124m\"\u001b[39m: by, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalue\u001b[39m\u001b[38;5;124m\"\u001b[39m: value})[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalue\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\selenium\\webdriver\\remote\\webdriver.py:347\u001b[0m, in \u001b[0;36mWebDriver.execute\u001b[1;34m(self, driver_command, params)\u001b[0m\n\u001b[0;32m    345\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcommand_executor\u001b[38;5;241m.\u001b[39mexecute(driver_command, params)\n\u001b[0;32m    346\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m response:\n\u001b[1;32m--> 347\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39merror_handler\u001b[38;5;241m.\u001b[39mcheck_response(response)\n\u001b[0;32m    348\u001b[0m     response[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalue\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_unwrap_value(response\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalue\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[0;32m    349\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\selenium\\webdriver\\remote\\errorhandler.py:229\u001b[0m, in \u001b[0;36mErrorHandler.check_response\u001b[1;34m(self, response)\u001b[0m\n\u001b[0;32m    227\u001b[0m         alert_text \u001b[38;5;241m=\u001b[39m value[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124malert\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    228\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exception_class(message, screen, stacktrace, alert_text)  \u001b[38;5;66;03m# type: ignore[call-arg]  # mypy is not smart enough here\u001b[39;00m\n\u001b[1;32m--> 229\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m exception_class(message, screen, stacktrace)\n",
      "\u001b[1;31mNoSuchWindowException\u001b[0m: Message: no such window: target window already closed\nfrom unknown error: web view not found\n  (Session info: chrome=123.0.6312.106)\nStacktrace:\n\tGetHandleVerifier [0x00BB4CE3+225091]\n\t(No symbol) [0x00AE4E31]\n\t(No symbol) [0x00989A7A]\n\t(No symbol) [0x0096E312]\n\t(No symbol) [0x009E517B]\n\t(No symbol) [0x009F55A6]\n\t(No symbol) [0x009DF2F6]\n\t(No symbol) [0x009B79B9]\n\t(No symbol) [0x009B879D]\n\tsqlite3_dbdata_init [0x01029A83+4064547]\n\tsqlite3_dbdata_init [0x0103108A+4094762]\n\tsqlite3_dbdata_init [0x0102B988+4072488]\n\tsqlite3_dbdata_init [0x00D2C9E9+930953]\n\t(No symbol) [0x00AF0804]\n\t(No symbol) [0x00AEAD28]\n\t(No symbol) [0x00AEAE51]\n\t(No symbol) [0x00ADCAC0]\n\tBaseThreadInitThunk [0x75497BA9+25]\n\tRtlInitializeExceptionChain [0x7787BDAB+107]\n\tRtlClearBits [0x7787BD2F+191]\n"
     ]
    }
   ],
   "source": [
    "# 페이지 번호 클릭 테스트\n",
    "driver.find_element(By.CSS_SELECTOR, '#contentData > div > div.movie-idv-story > nav > a.control.last').click() # 첫 페이지 CSS 선택자\n",
    "time.sleep(PAUSE_TIME)\n",
    "total_page_num = int(driver.find_element(By.CSS_SELECTOR, '#contentData > div > div.movie-idv-story > nav > strong').text) # 마지막 페이지 CSS 선택자 -> for문 반복회수 확인\n",
    "\n",
    "print('전체 페이지 수:', total_page_num)\n",
    "print('-'*80)\n",
    "# 다시 첫 페이지로 이동\n",
    "driver.find_element(By.CSS_SELECTOR, '#contentData > div > div.movie-idv-story > nav > a.control.first').click()\n",
    "time.sleep(PAUSE_TIME)\n",
    "\n",
    "ratings = [] # 평점 정보 저장할 리스트\n",
    "comments = [] # 관람평\n",
    "\n",
    "THE_LAST_PAGE = 20 #마지막 페이지 20으로 조정\n",
    "\n",
    "# 다음 클릭이 이루어질 a 태그의 순서(첫 페이지는 a 태그가 아닌 strong 태그이기 때문에 첫 클릭이 이뤄질 태그는 2부터 시작)\n",
    "next_a_tag = 2 # 1, 11, 21, ... 첫 페이지는 클릭 불가.\n",
    "\n",
    "for i in range(1, total_page_num+1):\n",
    "    if i > THE_LAST_PAGE: break\n",
    "    print(f'{i}페이지 평점 및 리뷰 정보 수집')\n",
    "    \n",
    "    bs = BeautifulSoup(driver.page_source, 'lxml')\n",
    "    onesReviewBox = bs.find_all('li', attrs={'class':'type01 oneContentTag'}) # 1인 관람평 및 평점 박스\n",
    "    \n",
    "    # 첫 페이지 10개 리뷰 저장\n",
    "    for c in onesReviewBox:\n",
    "        rating = int(c.find('div', attrs={'class':'story-point'}).text)\n",
    "        comment = c.find('div', attrs={'class':'story-txt'}).text.strip() # strip으로 리뷰 내 엔터 등의 공백 제거\n",
    "    #    print(rating, comment) 출력 결과 확인\n",
    "        ratings.append(rating)\n",
    "        comments.append(comment)\n",
    "\n",
    "    if not i%10: # 10번째 페이지 정보 수집이 끝나면(인덱스가 10의 배수이면)\n",
    "        driver.find_element(By.CSS_SELECTOR, '#contentData > div > div.movie-idv-story > nav > a.control.next').click() # 다음 10페이지 보기 클릭\n",
    "        time.sleep(PAUSE_TIME)\n",
    "        next_a_tag = 4 # 다음 10페이지에서 그 다음 클릭이 이뤄질 a 태그의 순서는 4가 됨(다음 클릭할 때 페이지 링크 앞에 <<, <, 첫 페이지가 있기 때문)\n",
    "        continue\n",
    "    \n",
    "    #    다음 페이지 번호 클릭\n",
    "    driver.find_element(By.CSS_SELECTOR, f'#contentData > div > div.movie-idv-story > nav > a:nth-child({next_a_tag})').click()\n",
    "    next_a_tag += 1\n",
    "    time.sleep(PAUSE_TIME)\n",
    "\n",
    "driver.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "9d7e11aa-095f-4b74-9971-38d83c0d979e",
   "metadata": {},
   "outputs": [
    {
     "ename": "ZeroDivisionError",
     "evalue": "division by zero",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mZeroDivisionError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[43], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m관람객 평점: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28msum\u001b[39m(ratings)\u001b[38;5;241m/\u001b[39m\u001b[38;5;28mlen\u001b[39m(ratings)\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.1f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m점\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mcsv\u001b[39;00m \u001b[38;5;66;03m# 대용량 데이터 -> 엑셀파일 comma sperate value\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mratings.csv\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f: \u001b[38;5;66;03m# 'w'모드: 텍스트 모드\u001b[39;00m\n",
      "\u001b[1;31mZeroDivisionError\u001b[0m: division by zero"
     ]
    }
   ],
   "source": [
    "print(f'관람객 평점: {sum(ratings)/len(ratings):.1f}점')\n",
    "\n",
    "import csv # 대용량 데이터 -> 엑셀파일 comma sperate value\n",
    "\n",
    "with open ('ratings.csv', 'w') as f: # 'w'모드: 텍스트 모드\n",
    "    writer = csv.writer(f) # csv 파일로 사용가능한 객체 생성\n",
    "    for rating in ratings:\n",
    "        writer.writerow([rating]) # 한 행에 쓸 데이터는 리스트 형태로 담아야 함\n",
    "print('평점 저장 완료')\n",
    "\n",
    "with open('comment.txt', 'w', encoding='utf-8') as f:\n",
    "    for comment in comments:\n",
    "        f.write(comment + '\\n')\n",
    "print('감상평 저장 완료')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
